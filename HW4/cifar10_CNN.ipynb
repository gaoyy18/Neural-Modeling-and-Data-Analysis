{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK_1: Convolutional Neural Networks\n",
    "---\n",
    "In this notebook, we train a **CNN** to classify images from the CIFAR-10 database.\n",
    "\n",
    "The images in this database are small color images that fall into one of ten classes; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for CUDA( you can use either GPU or CPU as you like )\n",
    "\n",
    "Since these are larger (32x32x3) images, it may prove useful to speed up your training time by using a GPU. CUDA is a parallel computing platform and CUDA Tensors are the same as typical Tensors, only they utilize GPU's for computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "\n",
    "device = torch.device(\"cuda\" if train_on_gpu else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load the Data\n",
    "\n",
    "If you're not familiar with the Cifar-10, you may find it useful to look at: http://www.cs.toronto.edu/~kriz/cifar.html . Or you could search it by yourself. \n",
    "\n",
    "You can load the dataset through **datasets.CIFAR10** in **torchvision**.\n",
    "\n",
    "\n",
    "#### TODO: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# # To avoid ssl.SSLCertVerificationError\n",
    "# import ssl\n",
    "# ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 首先需要构建dataset，构建dataset时可以利用transforms做数据增强，在这里采用了对CIFAR-10数据集常用的数据增强方法：随机裁剪和水平翻转，以及normalize操作。\n",
    "transforms并不是直接扩充样本量，而是各种变换以一定概率直接作用在原图片上，没有生成新样本，只不过在一次次迭代过程中，各种变换随机发生，从而导致每次Epoch读进来的数据都是不一样的，从大数定理的角度相当于扩充了样本量。\n",
    "\n",
    "\n",
    "2. 将dataset传入到dataloader中，后续训练和测试通过enumerate dataloader来喂数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset: Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomCrop(size=(32, 32), padding=4)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n",
      "           )\n",
      "testset: Dataset CIFAR10\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n",
      "           )\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "torch.Size([3, 32, 32])\n",
      "frog\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F88B2B627F0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View the dataset info and transformed image example\n",
    "print('trainset:', trainset)\n",
    "print('testset:', testset)\n",
    "\n",
    "print(trainset.classes)\n",
    "print(trainset[0][0].shape)\n",
    "print(trainset.classes[trainset[0][1]])\n",
    "transform_toimg = transforms.ToPILImage()\n",
    "img = transform_toimg(trainset[0][0])\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Define the Network Architecture\n",
    "\n",
    "This time, you'll define a CNN architecture. You may use \n",
    "* [Convolutional layers](https://pytorch.org/docs/stable/nn.html#conv2d), which can be thought of as stack of filtered images.\n",
    "* [Maxpooling layers](https://pytorch.org/docs/stable/nn.html#maxpool2d), which reduce the x-y size of an input, keeping only the most _active_ pixels from the previous layer.\n",
    "* The usual Linear + Dropout layers to avoid overfitting and produce a 10-dim output.\n",
    "\n",
    "\n",
    "#### Output volume for a convolutional layer\n",
    "\n",
    "To compute the output size of a given convolutional layer we can perform the following calculation:\n",
    "> We can compute the spatial size of the output volume as a function of the input volume size (W), the kernel/filter size (F), the stride with which they are applied (S), and the amount of zero padding used (P) on the border. The correct formula for calculating how many neurons define the output_W is given by `(W−F+2P)/S+1`. \n",
    "\n",
    "For example for a 7x7 input and a 3x3 filter with stride 1 and pad 0 we would get a 5x5 output. With stride 2 we would get a 3x3 output.\n",
    "\n",
    "#### TODO: Define a model with multiple convolutional layers and an output layer for image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CnnNet(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout2): Dropout(p=0.25, inplace=False)\n",
      "  (fc1): Linear(in_features=4608, out_features=128, bias=True)\n",
      "  (dropout3): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "test output size:\n",
      " torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "#Define a CNN model\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "class CnnNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CnnNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 128, 1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(6 * 6 * 128, 128)\n",
    "        self.dropout3 = nn.Dropout(0.25)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = CnnNet()\n",
    "print(model)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if train_on_gpu:\n",
    "    model.cuda()\n",
    "\n",
    "# test\n",
    "def test_CnnNet():\n",
    "    model = CnnNet()\n",
    "    y = model(torch.randn(10, 3, 32, 32))\n",
    "    print('test output size:\\n', y.size())\n",
    "test_CnnNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify [Loss Function](http://pytorch.org/docs/stable/nn.html#loss-functions) and [Optimizer](http://pytorch.org/docs/stable/optim.html)\n",
    "\n",
    "Decide on a loss and optimization function that is best suited for this classification task. Pay attention to the value for **learning rate** as this value determines how your model converges to a small error.\n",
    "\n",
    "#### TODO: Define the loss and optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "lr = 1.0    # Note the default learning rate for optimizer Adadelta is 1.0\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. CrossEntropyLoss等于对输出做F.log_softmax(x, dim=1)再做nll_loss，注意对应的target都不是one-hot类型的。\n",
    "2. 暂定训练200个epoch，学习率余弦退火。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train the Network\n",
    "\n",
    "Remember to look at how the loss decreases over time and print them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要使用tensorboard观察train loss。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 1.313801\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.435543\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.258914\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.220180\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.197856\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.248019\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.174956\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.147141\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.145261\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.152931\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.169389\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.171086\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.220663\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.200388\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.160090\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.008212\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.083390\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.973850\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.242392\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 1.105383\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.367159\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 1.095600\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 1.029588\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 1.081225\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 1.010365\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.792289\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.993833\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.982394\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 1.034971\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.951296\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.869543\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.993915\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 1.035195\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.997433\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.927784\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.753550\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.946993\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.654245\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.723552\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.826034\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.706510\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 0.701567\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.925309\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 0.745133\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.738527\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 0.757164\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 0.858444\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 0.712079\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 1.082815\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 0.664525\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 0.843618\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 0.611683\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.708148\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 0.649711\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 0.618193\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 0.699100\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.696847\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 0.772911\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 0.773285\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 0.780009\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 0.851843\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 0.669577\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 0.702895\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 0.728552\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 0.768853\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 0.846166\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 0.673971\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 0.630765\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 0.753419\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 0.692726\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 0.650271\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 0.810079\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.928071\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 0.530046\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 0.762581\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 0.716338\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 0.649284\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 0.665066\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 0.742723\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 0.801443\n",
      "Train Epoch: 21 [0/50000 (0%)]\tLoss: 0.799646\n",
      "Train Epoch: 21 [12800/50000 (26%)]\tLoss: 0.788963\n",
      "Train Epoch: 21 [25600/50000 (51%)]\tLoss: 0.815518\n",
      "Train Epoch: 21 [38400/50000 (77%)]\tLoss: 0.792675\n",
      "Train Epoch: 22 [0/50000 (0%)]\tLoss: 0.737533\n",
      "Train Epoch: 22 [12800/50000 (26%)]\tLoss: 0.680673\n",
      "Train Epoch: 22 [25600/50000 (51%)]\tLoss: 0.594136\n",
      "Train Epoch: 22 [38400/50000 (77%)]\tLoss: 0.613246\n",
      "Train Epoch: 23 [0/50000 (0%)]\tLoss: 0.628059\n",
      "Train Epoch: 23 [12800/50000 (26%)]\tLoss: 0.791284\n",
      "Train Epoch: 23 [25600/50000 (51%)]\tLoss: 0.687353\n",
      "Train Epoch: 23 [38400/50000 (77%)]\tLoss: 0.614265\n",
      "Train Epoch: 24 [0/50000 (0%)]\tLoss: 0.834377\n",
      "Train Epoch: 24 [12800/50000 (26%)]\tLoss: 0.603777\n",
      "Train Epoch: 24 [25600/50000 (51%)]\tLoss: 0.563128\n",
      "Train Epoch: 24 [38400/50000 (77%)]\tLoss: 0.921873\n",
      "Train Epoch: 25 [0/50000 (0%)]\tLoss: 0.494225\n",
      "Train Epoch: 25 [12800/50000 (26%)]\tLoss: 0.658208\n",
      "Train Epoch: 25 [25600/50000 (51%)]\tLoss: 0.735664\n",
      "Train Epoch: 25 [38400/50000 (77%)]\tLoss: 0.806758\n",
      "Train Epoch: 26 [0/50000 (0%)]\tLoss: 0.806753\n",
      "Train Epoch: 26 [12800/50000 (26%)]\tLoss: 0.649727\n",
      "Train Epoch: 26 [25600/50000 (51%)]\tLoss: 0.842813\n",
      "Train Epoch: 26 [38400/50000 (77%)]\tLoss: 0.668007\n",
      "Train Epoch: 27 [0/50000 (0%)]\tLoss: 0.608185\n",
      "Train Epoch: 27 [12800/50000 (26%)]\tLoss: 0.790306\n",
      "Train Epoch: 27 [25600/50000 (51%)]\tLoss: 0.731953\n",
      "Train Epoch: 27 [38400/50000 (77%)]\tLoss: 0.627782\n",
      "Train Epoch: 28 [0/50000 (0%)]\tLoss: 0.748317\n",
      "Train Epoch: 28 [12800/50000 (26%)]\tLoss: 0.632983\n",
      "Train Epoch: 28 [25600/50000 (51%)]\tLoss: 0.656099\n",
      "Train Epoch: 28 [38400/50000 (77%)]\tLoss: 0.608280\n",
      "Train Epoch: 29 [0/50000 (0%)]\tLoss: 0.590126\n",
      "Train Epoch: 29 [12800/50000 (26%)]\tLoss: 0.679301\n",
      "Train Epoch: 29 [25600/50000 (51%)]\tLoss: 0.643378\n",
      "Train Epoch: 29 [38400/50000 (77%)]\tLoss: 0.425036\n",
      "Train Epoch: 30 [0/50000 (0%)]\tLoss: 0.663460\n",
      "Train Epoch: 30 [12800/50000 (26%)]\tLoss: 0.440576\n",
      "Train Epoch: 30 [25600/50000 (51%)]\tLoss: 0.496114\n",
      "Train Epoch: 30 [38400/50000 (77%)]\tLoss: 0.563309\n",
      "Train Epoch: 31 [0/50000 (0%)]\tLoss: 0.713490\n",
      "Train Epoch: 31 [12800/50000 (26%)]\tLoss: 0.539547\n",
      "Train Epoch: 31 [25600/50000 (51%)]\tLoss: 0.575479\n",
      "Train Epoch: 31 [38400/50000 (77%)]\tLoss: 0.633162\n",
      "Train Epoch: 32 [0/50000 (0%)]\tLoss: 0.850327\n",
      "Train Epoch: 32 [12800/50000 (26%)]\tLoss: 0.708409\n",
      "Train Epoch: 32 [25600/50000 (51%)]\tLoss: 0.832042\n",
      "Train Epoch: 32 [38400/50000 (77%)]\tLoss: 0.527537\n",
      "Train Epoch: 33 [0/50000 (0%)]\tLoss: 0.703979\n",
      "Train Epoch: 33 [12800/50000 (26%)]\tLoss: 0.608725\n",
      "Train Epoch: 33 [25600/50000 (51%)]\tLoss: 0.619887\n",
      "Train Epoch: 33 [38400/50000 (77%)]\tLoss: 0.699498\n",
      "Train Epoch: 34 [0/50000 (0%)]\tLoss: 0.548988\n",
      "Train Epoch: 34 [12800/50000 (26%)]\tLoss: 0.457227\n",
      "Train Epoch: 34 [25600/50000 (51%)]\tLoss: 0.536021\n",
      "Train Epoch: 34 [38400/50000 (77%)]\tLoss: 0.601756\n",
      "Train Epoch: 35 [0/50000 (0%)]\tLoss: 0.594611\n",
      "Train Epoch: 35 [12800/50000 (26%)]\tLoss: 0.783818\n",
      "Train Epoch: 35 [25600/50000 (51%)]\tLoss: 0.541887\n",
      "Train Epoch: 35 [38400/50000 (77%)]\tLoss: 0.766469\n",
      "Train Epoch: 36 [0/50000 (0%)]\tLoss: 0.640197\n",
      "Train Epoch: 36 [12800/50000 (26%)]\tLoss: 0.715382\n",
      "Train Epoch: 36 [25600/50000 (51%)]\tLoss: 0.545568\n",
      "Train Epoch: 36 [38400/50000 (77%)]\tLoss: 0.678549\n",
      "Train Epoch: 37 [0/50000 (0%)]\tLoss: 0.455244\n",
      "Train Epoch: 37 [12800/50000 (26%)]\tLoss: 0.645500\n",
      "Train Epoch: 37 [25600/50000 (51%)]\tLoss: 0.713676\n",
      "Train Epoch: 37 [38400/50000 (77%)]\tLoss: 0.591039\n",
      "Train Epoch: 38 [0/50000 (0%)]\tLoss: 0.631045\n",
      "Train Epoch: 38 [12800/50000 (26%)]\tLoss: 0.463820\n",
      "Train Epoch: 38 [25600/50000 (51%)]\tLoss: 0.769848\n",
      "Train Epoch: 38 [38400/50000 (77%)]\tLoss: 0.369650\n",
      "Train Epoch: 39 [0/50000 (0%)]\tLoss: 0.507730\n",
      "Train Epoch: 39 [12800/50000 (26%)]\tLoss: 0.582185\n",
      "Train Epoch: 39 [25600/50000 (51%)]\tLoss: 0.553724\n",
      "Train Epoch: 39 [38400/50000 (77%)]\tLoss: 0.533805\n",
      "Train Epoch: 40 [0/50000 (0%)]\tLoss: 0.406849\n",
      "Train Epoch: 40 [12800/50000 (26%)]\tLoss: 0.635082\n",
      "Train Epoch: 40 [25600/50000 (51%)]\tLoss: 0.626652\n",
      "Train Epoch: 40 [38400/50000 (77%)]\tLoss: 0.688386\n",
      "Train Epoch: 41 [0/50000 (0%)]\tLoss: 0.442586\n",
      "Train Epoch: 41 [12800/50000 (26%)]\tLoss: 0.661764\n",
      "Train Epoch: 41 [25600/50000 (51%)]\tLoss: 0.641050\n",
      "Train Epoch: 41 [38400/50000 (77%)]\tLoss: 0.691334\n",
      "Train Epoch: 42 [0/50000 (0%)]\tLoss: 0.485770\n",
      "Train Epoch: 42 [12800/50000 (26%)]\tLoss: 0.508346\n",
      "Train Epoch: 42 [25600/50000 (51%)]\tLoss: 0.532502\n",
      "Train Epoch: 42 [38400/50000 (77%)]\tLoss: 0.647993\n",
      "Train Epoch: 43 [0/50000 (0%)]\tLoss: 0.523076\n",
      "Train Epoch: 43 [12800/50000 (26%)]\tLoss: 0.618693\n",
      "Train Epoch: 43 [25600/50000 (51%)]\tLoss: 0.684182\n",
      "Train Epoch: 43 [38400/50000 (77%)]\tLoss: 0.457597\n",
      "Train Epoch: 44 [0/50000 (0%)]\tLoss: 0.634263\n",
      "Train Epoch: 44 [12800/50000 (26%)]\tLoss: 0.501445\n",
      "Train Epoch: 44 [25600/50000 (51%)]\tLoss: 0.573412\n",
      "Train Epoch: 44 [38400/50000 (77%)]\tLoss: 0.604541\n",
      "Train Epoch: 45 [0/50000 (0%)]\tLoss: 0.584778\n",
      "Train Epoch: 45 [12800/50000 (26%)]\tLoss: 0.473146\n",
      "Train Epoch: 45 [25600/50000 (51%)]\tLoss: 0.536493\n",
      "Train Epoch: 45 [38400/50000 (77%)]\tLoss: 0.862471\n",
      "Train Epoch: 46 [0/50000 (0%)]\tLoss: 0.742453\n",
      "Train Epoch: 46 [12800/50000 (26%)]\tLoss: 0.558055\n",
      "Train Epoch: 46 [25600/50000 (51%)]\tLoss: 0.729319\n",
      "Train Epoch: 46 [38400/50000 (77%)]\tLoss: 0.395616\n",
      "Train Epoch: 47 [0/50000 (0%)]\tLoss: 0.535139\n",
      "Train Epoch: 47 [12800/50000 (26%)]\tLoss: 0.701532\n",
      "Train Epoch: 47 [25600/50000 (51%)]\tLoss: 0.715578\n",
      "Train Epoch: 47 [38400/50000 (77%)]\tLoss: 0.500166\n",
      "Train Epoch: 48 [0/50000 (0%)]\tLoss: 0.511755\n",
      "Train Epoch: 48 [12800/50000 (26%)]\tLoss: 0.583709\n",
      "Train Epoch: 48 [25600/50000 (51%)]\tLoss: 0.431960\n",
      "Train Epoch: 48 [38400/50000 (77%)]\tLoss: 0.590545\n",
      "Train Epoch: 49 [0/50000 (0%)]\tLoss: 0.624731\n",
      "Train Epoch: 49 [12800/50000 (26%)]\tLoss: 0.599572\n",
      "Train Epoch: 49 [25600/50000 (51%)]\tLoss: 0.558244\n",
      "Train Epoch: 49 [38400/50000 (77%)]\tLoss: 0.529670\n",
      "Train Epoch: 50 [0/50000 (0%)]\tLoss: 0.482955\n",
      "Train Epoch: 50 [12800/50000 (26%)]\tLoss: 0.448982\n",
      "Train Epoch: 50 [25600/50000 (51%)]\tLoss: 0.569747\n",
      "Train Epoch: 50 [38400/50000 (77%)]\tLoss: 0.592233\n",
      "Train Epoch: 51 [0/50000 (0%)]\tLoss: 0.746834\n",
      "Train Epoch: 51 [12800/50000 (26%)]\tLoss: 0.506524\n",
      "Train Epoch: 51 [25600/50000 (51%)]\tLoss: 0.423897\n",
      "Train Epoch: 51 [38400/50000 (77%)]\tLoss: 0.503922\n",
      "Train Epoch: 52 [0/50000 (0%)]\tLoss: 0.551629\n",
      "Train Epoch: 52 [12800/50000 (26%)]\tLoss: 0.444782\n",
      "Train Epoch: 52 [25600/50000 (51%)]\tLoss: 0.665672\n",
      "Train Epoch: 52 [38400/50000 (77%)]\tLoss: 0.529374\n",
      "Train Epoch: 53 [0/50000 (0%)]\tLoss: 0.436644\n",
      "Train Epoch: 53 [12800/50000 (26%)]\tLoss: 0.847410\n",
      "Train Epoch: 53 [25600/50000 (51%)]\tLoss: 0.537147\n",
      "Train Epoch: 53 [38400/50000 (77%)]\tLoss: 0.439410\n",
      "Train Epoch: 54 [0/50000 (0%)]\tLoss: 0.570595\n",
      "Train Epoch: 54 [12800/50000 (26%)]\tLoss: 0.751658\n",
      "Train Epoch: 54 [25600/50000 (51%)]\tLoss: 0.591613\n",
      "Train Epoch: 54 [38400/50000 (77%)]\tLoss: 0.510105\n",
      "Train Epoch: 55 [0/50000 (0%)]\tLoss: 0.617387\n",
      "Train Epoch: 55 [12800/50000 (26%)]\tLoss: 0.594933\n",
      "Train Epoch: 55 [25600/50000 (51%)]\tLoss: 0.437771\n",
      "Train Epoch: 55 [38400/50000 (77%)]\tLoss: 0.548860\n",
      "Train Epoch: 56 [0/50000 (0%)]\tLoss: 0.561874\n",
      "Train Epoch: 56 [12800/50000 (26%)]\tLoss: 0.622153\n",
      "Train Epoch: 56 [25600/50000 (51%)]\tLoss: 0.654668\n",
      "Train Epoch: 56 [38400/50000 (77%)]\tLoss: 0.662529\n",
      "Train Epoch: 57 [0/50000 (0%)]\tLoss: 0.803086\n",
      "Train Epoch: 57 [12800/50000 (26%)]\tLoss: 0.599714\n",
      "Train Epoch: 57 [25600/50000 (51%)]\tLoss: 0.449223\n",
      "Train Epoch: 57 [38400/50000 (77%)]\tLoss: 0.482442\n",
      "Train Epoch: 58 [0/50000 (0%)]\tLoss: 0.467352\n",
      "Train Epoch: 58 [12800/50000 (26%)]\tLoss: 0.574072\n",
      "Train Epoch: 58 [25600/50000 (51%)]\tLoss: 0.633521\n",
      "Train Epoch: 58 [38400/50000 (77%)]\tLoss: 0.580987\n",
      "Train Epoch: 59 [0/50000 (0%)]\tLoss: 0.398680\n",
      "Train Epoch: 59 [12800/50000 (26%)]\tLoss: 0.544008\n",
      "Train Epoch: 59 [25600/50000 (51%)]\tLoss: 0.525087\n",
      "Train Epoch: 59 [38400/50000 (77%)]\tLoss: 0.492054\n",
      "Train Epoch: 60 [0/50000 (0%)]\tLoss: 0.571716\n",
      "Train Epoch: 60 [12800/50000 (26%)]\tLoss: 0.479958\n",
      "Train Epoch: 60 [25600/50000 (51%)]\tLoss: 0.446123\n",
      "Train Epoch: 60 [38400/50000 (77%)]\tLoss: 0.576769\n",
      "Train Epoch: 61 [0/50000 (0%)]\tLoss: 0.447519\n",
      "Train Epoch: 61 [12800/50000 (26%)]\tLoss: 0.656467\n",
      "Train Epoch: 61 [25600/50000 (51%)]\tLoss: 0.709451\n",
      "Train Epoch: 61 [38400/50000 (77%)]\tLoss: 0.535802\n",
      "Train Epoch: 62 [0/50000 (0%)]\tLoss: 0.534848\n",
      "Train Epoch: 62 [12800/50000 (26%)]\tLoss: 0.473258\n",
      "Train Epoch: 62 [25600/50000 (51%)]\tLoss: 0.435042\n",
      "Train Epoch: 62 [38400/50000 (77%)]\tLoss: 0.466425\n",
      "Train Epoch: 63 [0/50000 (0%)]\tLoss: 0.557818\n",
      "Train Epoch: 63 [12800/50000 (26%)]\tLoss: 0.611341\n",
      "Train Epoch: 63 [25600/50000 (51%)]\tLoss: 0.549617\n",
      "Train Epoch: 63 [38400/50000 (77%)]\tLoss: 0.577609\n",
      "Train Epoch: 64 [0/50000 (0%)]\tLoss: 0.623358\n",
      "Train Epoch: 64 [12800/50000 (26%)]\tLoss: 0.418414\n",
      "Train Epoch: 64 [25600/50000 (51%)]\tLoss: 0.606891\n",
      "Train Epoch: 64 [38400/50000 (77%)]\tLoss: 0.568371\n",
      "Train Epoch: 65 [0/50000 (0%)]\tLoss: 0.605608\n",
      "Train Epoch: 65 [12800/50000 (26%)]\tLoss: 0.576219\n",
      "Train Epoch: 65 [25600/50000 (51%)]\tLoss: 0.483202\n",
      "Train Epoch: 65 [38400/50000 (77%)]\tLoss: 0.569430\n",
      "Train Epoch: 66 [0/50000 (0%)]\tLoss: 0.512375\n",
      "Train Epoch: 66 [12800/50000 (26%)]\tLoss: 0.560998\n",
      "Train Epoch: 66 [25600/50000 (51%)]\tLoss: 0.461195\n",
      "Train Epoch: 66 [38400/50000 (77%)]\tLoss: 0.619268\n",
      "Train Epoch: 67 [0/50000 (0%)]\tLoss: 0.588797\n",
      "Train Epoch: 67 [12800/50000 (26%)]\tLoss: 0.476902\n",
      "Train Epoch: 67 [25600/50000 (51%)]\tLoss: 0.626628\n",
      "Train Epoch: 67 [38400/50000 (77%)]\tLoss: 0.559005\n",
      "Train Epoch: 68 [0/50000 (0%)]\tLoss: 0.453343\n",
      "Train Epoch: 68 [12800/50000 (26%)]\tLoss: 0.343488\n",
      "Train Epoch: 68 [25600/50000 (51%)]\tLoss: 0.533970\n",
      "Train Epoch: 68 [38400/50000 (77%)]\tLoss: 0.534432\n",
      "Train Epoch: 69 [0/50000 (0%)]\tLoss: 0.603963\n",
      "Train Epoch: 69 [12800/50000 (26%)]\tLoss: 0.394847\n",
      "Train Epoch: 69 [25600/50000 (51%)]\tLoss: 0.660976\n",
      "Train Epoch: 69 [38400/50000 (77%)]\tLoss: 0.520373\n",
      "Train Epoch: 70 [0/50000 (0%)]\tLoss: 0.516429\n",
      "Train Epoch: 70 [12800/50000 (26%)]\tLoss: 0.480887\n",
      "Train Epoch: 70 [25600/50000 (51%)]\tLoss: 0.483967\n",
      "Train Epoch: 70 [38400/50000 (77%)]\tLoss: 0.542147\n",
      "Train Epoch: 71 [0/50000 (0%)]\tLoss: 0.557542\n",
      "Train Epoch: 71 [12800/50000 (26%)]\tLoss: 0.484882\n",
      "Train Epoch: 71 [25600/50000 (51%)]\tLoss: 0.458973\n",
      "Train Epoch: 71 [38400/50000 (77%)]\tLoss: 0.386523\n",
      "Train Epoch: 72 [0/50000 (0%)]\tLoss: 0.535119\n",
      "Train Epoch: 72 [12800/50000 (26%)]\tLoss: 0.405405\n",
      "Train Epoch: 72 [25600/50000 (51%)]\tLoss: 0.541187\n",
      "Train Epoch: 72 [38400/50000 (77%)]\tLoss: 0.541837\n",
      "Train Epoch: 73 [0/50000 (0%)]\tLoss: 0.575086\n",
      "Train Epoch: 73 [12800/50000 (26%)]\tLoss: 0.553033\n",
      "Train Epoch: 73 [25600/50000 (51%)]\tLoss: 0.281135\n",
      "Train Epoch: 73 [38400/50000 (77%)]\tLoss: 0.358461\n",
      "Train Epoch: 74 [0/50000 (0%)]\tLoss: 0.506670\n",
      "Train Epoch: 74 [12800/50000 (26%)]\tLoss: 0.490020\n",
      "Train Epoch: 74 [25600/50000 (51%)]\tLoss: 0.392980\n",
      "Train Epoch: 74 [38400/50000 (77%)]\tLoss: 0.365200\n",
      "Train Epoch: 75 [0/50000 (0%)]\tLoss: 0.526157\n",
      "Train Epoch: 75 [12800/50000 (26%)]\tLoss: 0.555761\n",
      "Train Epoch: 75 [25600/50000 (51%)]\tLoss: 0.574564\n",
      "Train Epoch: 75 [38400/50000 (77%)]\tLoss: 0.360852\n",
      "Train Epoch: 76 [0/50000 (0%)]\tLoss: 0.467072\n",
      "Train Epoch: 76 [12800/50000 (26%)]\tLoss: 0.429571\n",
      "Train Epoch: 76 [25600/50000 (51%)]\tLoss: 0.441920\n",
      "Train Epoch: 76 [38400/50000 (77%)]\tLoss: 0.415465\n",
      "Train Epoch: 77 [0/50000 (0%)]\tLoss: 0.493176\n",
      "Train Epoch: 77 [12800/50000 (26%)]\tLoss: 0.486346\n",
      "Train Epoch: 77 [25600/50000 (51%)]\tLoss: 0.443980\n",
      "Train Epoch: 77 [38400/50000 (77%)]\tLoss: 0.413406\n",
      "Train Epoch: 78 [0/50000 (0%)]\tLoss: 0.457171\n",
      "Train Epoch: 78 [12800/50000 (26%)]\tLoss: 0.442955\n",
      "Train Epoch: 78 [25600/50000 (51%)]\tLoss: 0.508169\n",
      "Train Epoch: 78 [38400/50000 (77%)]\tLoss: 0.457552\n",
      "Train Epoch: 79 [0/50000 (0%)]\tLoss: 0.447177\n",
      "Train Epoch: 79 [12800/50000 (26%)]\tLoss: 0.450795\n",
      "Train Epoch: 79 [25600/50000 (51%)]\tLoss: 0.486603\n",
      "Train Epoch: 79 [38400/50000 (77%)]\tLoss: 0.571007\n",
      "Train Epoch: 80 [0/50000 (0%)]\tLoss: 0.525150\n",
      "Train Epoch: 80 [12800/50000 (26%)]\tLoss: 0.495776\n",
      "Train Epoch: 80 [25600/50000 (51%)]\tLoss: 0.376436\n",
      "Train Epoch: 80 [38400/50000 (77%)]\tLoss: 0.642189\n",
      "Train Epoch: 81 [0/50000 (0%)]\tLoss: 0.373708\n",
      "Train Epoch: 81 [12800/50000 (26%)]\tLoss: 0.406437\n",
      "Train Epoch: 81 [25600/50000 (51%)]\tLoss: 0.471665\n",
      "Train Epoch: 81 [38400/50000 (77%)]\tLoss: 0.414964\n",
      "Train Epoch: 82 [0/50000 (0%)]\tLoss: 0.477657\n",
      "Train Epoch: 82 [12800/50000 (26%)]\tLoss: 0.483222\n",
      "Train Epoch: 82 [25600/50000 (51%)]\tLoss: 0.536827\n",
      "Train Epoch: 82 [38400/50000 (77%)]\tLoss: 0.299816\n",
      "Train Epoch: 83 [0/50000 (0%)]\tLoss: 0.514143\n",
      "Train Epoch: 83 [12800/50000 (26%)]\tLoss: 0.564096\n",
      "Train Epoch: 83 [25600/50000 (51%)]\tLoss: 0.641098\n",
      "Train Epoch: 83 [38400/50000 (77%)]\tLoss: 0.478955\n",
      "Train Epoch: 84 [0/50000 (0%)]\tLoss: 0.414188\n",
      "Train Epoch: 84 [12800/50000 (26%)]\tLoss: 0.434710\n",
      "Train Epoch: 84 [25600/50000 (51%)]\tLoss: 0.417909\n",
      "Train Epoch: 84 [38400/50000 (77%)]\tLoss: 0.591187\n",
      "Train Epoch: 85 [0/50000 (0%)]\tLoss: 0.473252\n",
      "Train Epoch: 85 [12800/50000 (26%)]\tLoss: 0.370635\n",
      "Train Epoch: 85 [25600/50000 (51%)]\tLoss: 0.429262\n",
      "Train Epoch: 85 [38400/50000 (77%)]\tLoss: 0.610170\n",
      "Train Epoch: 86 [0/50000 (0%)]\tLoss: 0.628347\n",
      "Train Epoch: 86 [12800/50000 (26%)]\tLoss: 0.455495\n",
      "Train Epoch: 86 [25600/50000 (51%)]\tLoss: 0.442465\n",
      "Train Epoch: 86 [38400/50000 (77%)]\tLoss: 0.371331\n",
      "Train Epoch: 87 [0/50000 (0%)]\tLoss: 0.504225\n",
      "Train Epoch: 87 [12800/50000 (26%)]\tLoss: 0.411414\n",
      "Train Epoch: 87 [25600/50000 (51%)]\tLoss: 0.390991\n",
      "Train Epoch: 87 [38400/50000 (77%)]\tLoss: 0.537123\n",
      "Train Epoch: 88 [0/50000 (0%)]\tLoss: 0.402095\n",
      "Train Epoch: 88 [12800/50000 (26%)]\tLoss: 0.501137\n",
      "Train Epoch: 88 [25600/50000 (51%)]\tLoss: 0.418213\n",
      "Train Epoch: 88 [38400/50000 (77%)]\tLoss: 0.517487\n",
      "Train Epoch: 89 [0/50000 (0%)]\tLoss: 0.587865\n",
      "Train Epoch: 89 [12800/50000 (26%)]\tLoss: 0.591614\n",
      "Train Epoch: 89 [25600/50000 (51%)]\tLoss: 0.390897\n",
      "Train Epoch: 89 [38400/50000 (77%)]\tLoss: 0.591589\n",
      "Train Epoch: 90 [0/50000 (0%)]\tLoss: 0.482096\n",
      "Train Epoch: 90 [12800/50000 (26%)]\tLoss: 0.403084\n",
      "Train Epoch: 90 [25600/50000 (51%)]\tLoss: 0.400353\n",
      "Train Epoch: 90 [38400/50000 (77%)]\tLoss: 0.419385\n",
      "Train Epoch: 91 [0/50000 (0%)]\tLoss: 0.440393\n",
      "Train Epoch: 91 [12800/50000 (26%)]\tLoss: 0.523614\n",
      "Train Epoch: 91 [25600/50000 (51%)]\tLoss: 0.609520\n",
      "Train Epoch: 91 [38400/50000 (77%)]\tLoss: 0.590865\n",
      "Train Epoch: 92 [0/50000 (0%)]\tLoss: 0.499630\n",
      "Train Epoch: 92 [12800/50000 (26%)]\tLoss: 0.408808\n",
      "Train Epoch: 92 [25600/50000 (51%)]\tLoss: 0.420332\n",
      "Train Epoch: 92 [38400/50000 (77%)]\tLoss: 0.336040\n",
      "Train Epoch: 93 [0/50000 (0%)]\tLoss: 0.412792\n",
      "Train Epoch: 93 [12800/50000 (26%)]\tLoss: 0.532002\n",
      "Train Epoch: 93 [25600/50000 (51%)]\tLoss: 0.595340\n",
      "Train Epoch: 93 [38400/50000 (77%)]\tLoss: 0.382487\n",
      "Train Epoch: 94 [0/50000 (0%)]\tLoss: 0.551069\n",
      "Train Epoch: 94 [12800/50000 (26%)]\tLoss: 0.429788\n",
      "Train Epoch: 94 [25600/50000 (51%)]\tLoss: 0.399761\n",
      "Train Epoch: 94 [38400/50000 (77%)]\tLoss: 0.510332\n",
      "Train Epoch: 95 [0/50000 (0%)]\tLoss: 0.510995\n",
      "Train Epoch: 95 [12800/50000 (26%)]\tLoss: 0.484850\n",
      "Train Epoch: 95 [25600/50000 (51%)]\tLoss: 0.428941\n",
      "Train Epoch: 95 [38400/50000 (77%)]\tLoss: 0.536602\n",
      "Train Epoch: 96 [0/50000 (0%)]\tLoss: 0.565653\n",
      "Train Epoch: 96 [12800/50000 (26%)]\tLoss: 0.402667\n",
      "Train Epoch: 96 [25600/50000 (51%)]\tLoss: 0.346735\n",
      "Train Epoch: 96 [38400/50000 (77%)]\tLoss: 0.411610\n",
      "Train Epoch: 97 [0/50000 (0%)]\tLoss: 0.451501\n",
      "Train Epoch: 97 [12800/50000 (26%)]\tLoss: 0.394748\n",
      "Train Epoch: 97 [25600/50000 (51%)]\tLoss: 0.625355\n",
      "Train Epoch: 97 [38400/50000 (77%)]\tLoss: 0.519082\n",
      "Train Epoch: 98 [0/50000 (0%)]\tLoss: 0.456710\n",
      "Train Epoch: 98 [12800/50000 (26%)]\tLoss: 0.407754\n",
      "Train Epoch: 98 [25600/50000 (51%)]\tLoss: 0.389220\n",
      "Train Epoch: 98 [38400/50000 (77%)]\tLoss: 0.461654\n",
      "Train Epoch: 99 [0/50000 (0%)]\tLoss: 0.435596\n",
      "Train Epoch: 99 [12800/50000 (26%)]\tLoss: 0.513415\n",
      "Train Epoch: 99 [25600/50000 (51%)]\tLoss: 0.458452\n",
      "Train Epoch: 99 [38400/50000 (77%)]\tLoss: 0.401380\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 0.448020\n",
      "Train Epoch: 100 [12800/50000 (26%)]\tLoss: 0.506636\n",
      "Train Epoch: 100 [25600/50000 (51%)]\tLoss: 0.476962\n",
      "Train Epoch: 100 [38400/50000 (77%)]\tLoss: 0.463249\n",
      "Train Epoch: 101 [0/50000 (0%)]\tLoss: 0.493499\n",
      "Train Epoch: 101 [12800/50000 (26%)]\tLoss: 0.476552\n",
      "Train Epoch: 101 [25600/50000 (51%)]\tLoss: 0.386656\n",
      "Train Epoch: 101 [38400/50000 (77%)]\tLoss: 0.459564\n",
      "Train Epoch: 102 [0/50000 (0%)]\tLoss: 0.518030\n",
      "Train Epoch: 102 [12800/50000 (26%)]\tLoss: 0.523986\n",
      "Train Epoch: 102 [25600/50000 (51%)]\tLoss: 0.382888\n",
      "Train Epoch: 102 [38400/50000 (77%)]\tLoss: 0.260973\n",
      "Train Epoch: 103 [0/50000 (0%)]\tLoss: 0.494655\n",
      "Train Epoch: 103 [12800/50000 (26%)]\tLoss: 0.371705\n",
      "Train Epoch: 103 [25600/50000 (51%)]\tLoss: 0.462297\n",
      "Train Epoch: 103 [38400/50000 (77%)]\tLoss: 0.418079\n",
      "Train Epoch: 104 [0/50000 (0%)]\tLoss: 0.361841\n",
      "Train Epoch: 104 [12800/50000 (26%)]\tLoss: 0.392098\n",
      "Train Epoch: 104 [25600/50000 (51%)]\tLoss: 0.431747\n",
      "Train Epoch: 104 [38400/50000 (77%)]\tLoss: 0.319670\n",
      "Train Epoch: 105 [0/50000 (0%)]\tLoss: 0.294531\n",
      "Train Epoch: 105 [12800/50000 (26%)]\tLoss: 0.441068\n",
      "Train Epoch: 105 [25600/50000 (51%)]\tLoss: 0.558724\n",
      "Train Epoch: 105 [38400/50000 (77%)]\tLoss: 0.491569\n",
      "Train Epoch: 106 [0/50000 (0%)]\tLoss: 0.519600\n",
      "Train Epoch: 106 [12800/50000 (26%)]\tLoss: 0.472424\n",
      "Train Epoch: 106 [25600/50000 (51%)]\tLoss: 0.468608\n",
      "Train Epoch: 106 [38400/50000 (77%)]\tLoss: 0.297904\n",
      "Train Epoch: 107 [0/50000 (0%)]\tLoss: 0.605323\n",
      "Train Epoch: 107 [12800/50000 (26%)]\tLoss: 0.397008\n",
      "Train Epoch: 107 [25600/50000 (51%)]\tLoss: 0.260173\n",
      "Train Epoch: 107 [38400/50000 (77%)]\tLoss: 0.377639\n",
      "Train Epoch: 108 [0/50000 (0%)]\tLoss: 0.523145\n",
      "Train Epoch: 108 [12800/50000 (26%)]\tLoss: 0.417398\n",
      "Train Epoch: 108 [25600/50000 (51%)]\tLoss: 0.435326\n",
      "Train Epoch: 108 [38400/50000 (77%)]\tLoss: 0.269705\n",
      "Train Epoch: 109 [0/50000 (0%)]\tLoss: 0.271470\n",
      "Train Epoch: 109 [12800/50000 (26%)]\tLoss: 0.333278\n",
      "Train Epoch: 109 [25600/50000 (51%)]\tLoss: 0.434508\n",
      "Train Epoch: 109 [38400/50000 (77%)]\tLoss: 0.362589\n",
      "Train Epoch: 110 [0/50000 (0%)]\tLoss: 0.432158\n",
      "Train Epoch: 110 [12800/50000 (26%)]\tLoss: 0.358071\n",
      "Train Epoch: 110 [25600/50000 (51%)]\tLoss: 0.406231\n",
      "Train Epoch: 110 [38400/50000 (77%)]\tLoss: 0.463790\n",
      "Train Epoch: 111 [0/50000 (0%)]\tLoss: 0.477861\n",
      "Train Epoch: 111 [12800/50000 (26%)]\tLoss: 0.277430\n",
      "Train Epoch: 111 [25600/50000 (51%)]\tLoss: 0.350375\n",
      "Train Epoch: 111 [38400/50000 (77%)]\tLoss: 0.595643\n",
      "Train Epoch: 112 [0/50000 (0%)]\tLoss: 0.447789\n",
      "Train Epoch: 112 [12800/50000 (26%)]\tLoss: 0.423158\n",
      "Train Epoch: 112 [25600/50000 (51%)]\tLoss: 0.544136\n",
      "Train Epoch: 112 [38400/50000 (77%)]\tLoss: 0.534262\n",
      "Train Epoch: 113 [0/50000 (0%)]\tLoss: 0.365116\n",
      "Train Epoch: 113 [12800/50000 (26%)]\tLoss: 0.386171\n",
      "Train Epoch: 113 [25600/50000 (51%)]\tLoss: 0.405716\n",
      "Train Epoch: 113 [38400/50000 (77%)]\tLoss: 0.519072\n",
      "Train Epoch: 114 [0/50000 (0%)]\tLoss: 0.470044\n",
      "Train Epoch: 114 [12800/50000 (26%)]\tLoss: 0.385363\n",
      "Train Epoch: 114 [25600/50000 (51%)]\tLoss: 0.517143\n",
      "Train Epoch: 114 [38400/50000 (77%)]\tLoss: 0.339361\n",
      "Train Epoch: 115 [0/50000 (0%)]\tLoss: 0.409123\n",
      "Train Epoch: 115 [12800/50000 (26%)]\tLoss: 0.511004\n",
      "Train Epoch: 115 [25600/50000 (51%)]\tLoss: 0.400367\n",
      "Train Epoch: 115 [38400/50000 (77%)]\tLoss: 0.621927\n",
      "Train Epoch: 116 [0/50000 (0%)]\tLoss: 0.484496\n",
      "Train Epoch: 116 [12800/50000 (26%)]\tLoss: 0.435186\n",
      "Train Epoch: 116 [25600/50000 (51%)]\tLoss: 0.407364\n",
      "Train Epoch: 116 [38400/50000 (77%)]\tLoss: 0.444443\n",
      "Train Epoch: 117 [0/50000 (0%)]\tLoss: 0.434156\n",
      "Train Epoch: 117 [12800/50000 (26%)]\tLoss: 0.472849\n",
      "Train Epoch: 117 [25600/50000 (51%)]\tLoss: 0.385554\n",
      "Train Epoch: 117 [38400/50000 (77%)]\tLoss: 0.257601\n",
      "Train Epoch: 118 [0/50000 (0%)]\tLoss: 0.330086\n",
      "Train Epoch: 118 [12800/50000 (26%)]\tLoss: 0.332631\n",
      "Train Epoch: 118 [25600/50000 (51%)]\tLoss: 0.568963\n",
      "Train Epoch: 118 [38400/50000 (77%)]\tLoss: 0.429516\n",
      "Train Epoch: 119 [0/50000 (0%)]\tLoss: 0.442128\n",
      "Train Epoch: 119 [12800/50000 (26%)]\tLoss: 0.496741\n",
      "Train Epoch: 119 [25600/50000 (51%)]\tLoss: 0.601331\n",
      "Train Epoch: 119 [38400/50000 (77%)]\tLoss: 0.344508\n",
      "Train Epoch: 120 [0/50000 (0%)]\tLoss: 0.410783\n",
      "Train Epoch: 120 [12800/50000 (26%)]\tLoss: 0.522976\n",
      "Train Epoch: 120 [25600/50000 (51%)]\tLoss: 0.396545\n",
      "Train Epoch: 120 [38400/50000 (77%)]\tLoss: 0.513154\n",
      "Train Epoch: 121 [0/50000 (0%)]\tLoss: 0.635186\n",
      "Train Epoch: 121 [12800/50000 (26%)]\tLoss: 0.427819\n",
      "Train Epoch: 121 [25600/50000 (51%)]\tLoss: 0.433159\n",
      "Train Epoch: 121 [38400/50000 (77%)]\tLoss: 0.351589\n",
      "Train Epoch: 122 [0/50000 (0%)]\tLoss: 0.259991\n",
      "Train Epoch: 122 [12800/50000 (26%)]\tLoss: 0.284421\n",
      "Train Epoch: 122 [25600/50000 (51%)]\tLoss: 0.472940\n",
      "Train Epoch: 122 [38400/50000 (77%)]\tLoss: 0.388031\n",
      "Train Epoch: 123 [0/50000 (0%)]\tLoss: 0.359168\n",
      "Train Epoch: 123 [12800/50000 (26%)]\tLoss: 0.499571\n",
      "Train Epoch: 123 [25600/50000 (51%)]\tLoss: 0.486255\n",
      "Train Epoch: 123 [38400/50000 (77%)]\tLoss: 0.366100\n",
      "Train Epoch: 124 [0/50000 (0%)]\tLoss: 0.425320\n",
      "Train Epoch: 124 [12800/50000 (26%)]\tLoss: 0.336060\n",
      "Train Epoch: 124 [25600/50000 (51%)]\tLoss: 0.313931\n",
      "Train Epoch: 124 [38400/50000 (77%)]\tLoss: 0.428521\n",
      "Train Epoch: 125 [0/50000 (0%)]\tLoss: 0.454050\n",
      "Train Epoch: 125 [12800/50000 (26%)]\tLoss: 0.473035\n",
      "Train Epoch: 125 [25600/50000 (51%)]\tLoss: 0.517771\n",
      "Train Epoch: 125 [38400/50000 (77%)]\tLoss: 0.439328\n",
      "Train Epoch: 126 [0/50000 (0%)]\tLoss: 0.432728\n",
      "Train Epoch: 126 [12800/50000 (26%)]\tLoss: 0.420592\n",
      "Train Epoch: 126 [25600/50000 (51%)]\tLoss: 0.441275\n",
      "Train Epoch: 126 [38400/50000 (77%)]\tLoss: 0.503400\n",
      "Train Epoch: 127 [0/50000 (0%)]\tLoss: 0.468977\n",
      "Train Epoch: 127 [12800/50000 (26%)]\tLoss: 0.401418\n",
      "Train Epoch: 127 [25600/50000 (51%)]\tLoss: 0.249189\n",
      "Train Epoch: 127 [38400/50000 (77%)]\tLoss: 0.389230\n",
      "Train Epoch: 128 [0/50000 (0%)]\tLoss: 0.466750\n",
      "Train Epoch: 128 [12800/50000 (26%)]\tLoss: 0.650277\n",
      "Train Epoch: 128 [25600/50000 (51%)]\tLoss: 0.345384\n",
      "Train Epoch: 128 [38400/50000 (77%)]\tLoss: 0.562583\n",
      "Train Epoch: 129 [0/50000 (0%)]\tLoss: 0.439209\n",
      "Train Epoch: 129 [12800/50000 (26%)]\tLoss: 0.541211\n",
      "Train Epoch: 129 [25600/50000 (51%)]\tLoss: 0.432289\n",
      "Train Epoch: 129 [38400/50000 (77%)]\tLoss: 0.399933\n",
      "Train Epoch: 130 [0/50000 (0%)]\tLoss: 0.368967\n",
      "Train Epoch: 130 [12800/50000 (26%)]\tLoss: 0.517520\n",
      "Train Epoch: 130 [25600/50000 (51%)]\tLoss: 0.387088\n",
      "Train Epoch: 130 [38400/50000 (77%)]\tLoss: 0.275523\n",
      "Train Epoch: 131 [0/50000 (0%)]\tLoss: 0.284158\n",
      "Train Epoch: 131 [12800/50000 (26%)]\tLoss: 0.410415\n",
      "Train Epoch: 131 [25600/50000 (51%)]\tLoss: 0.457717\n",
      "Train Epoch: 131 [38400/50000 (77%)]\tLoss: 0.410081\n",
      "Train Epoch: 132 [0/50000 (0%)]\tLoss: 0.433834\n",
      "Train Epoch: 132 [12800/50000 (26%)]\tLoss: 0.419185\n",
      "Train Epoch: 132 [25600/50000 (51%)]\tLoss: 0.304802\n",
      "Train Epoch: 132 [38400/50000 (77%)]\tLoss: 0.540248\n",
      "Train Epoch: 133 [0/50000 (0%)]\tLoss: 0.347128\n",
      "Train Epoch: 133 [12800/50000 (26%)]\tLoss: 0.629250\n",
      "Train Epoch: 133 [25600/50000 (51%)]\tLoss: 0.444603\n",
      "Train Epoch: 133 [38400/50000 (77%)]\tLoss: 0.369844\n",
      "Train Epoch: 134 [0/50000 (0%)]\tLoss: 0.287106\n",
      "Train Epoch: 134 [12800/50000 (26%)]\tLoss: 0.516933\n",
      "Train Epoch: 134 [25600/50000 (51%)]\tLoss: 0.262801\n",
      "Train Epoch: 134 [38400/50000 (77%)]\tLoss: 0.236520\n",
      "Train Epoch: 135 [0/50000 (0%)]\tLoss: 0.438011\n",
      "Train Epoch: 135 [12800/50000 (26%)]\tLoss: 0.444252\n",
      "Train Epoch: 135 [25600/50000 (51%)]\tLoss: 0.418260\n",
      "Train Epoch: 135 [38400/50000 (77%)]\tLoss: 0.509920\n",
      "Train Epoch: 136 [0/50000 (0%)]\tLoss: 0.343454\n",
      "Train Epoch: 136 [12800/50000 (26%)]\tLoss: 0.347075\n",
      "Train Epoch: 136 [25600/50000 (51%)]\tLoss: 0.389732\n",
      "Train Epoch: 136 [38400/50000 (77%)]\tLoss: 0.374202\n",
      "Train Epoch: 137 [0/50000 (0%)]\tLoss: 0.566615\n",
      "Train Epoch: 137 [12800/50000 (26%)]\tLoss: 0.378007\n",
      "Train Epoch: 137 [25600/50000 (51%)]\tLoss: 0.348665\n",
      "Train Epoch: 137 [38400/50000 (77%)]\tLoss: 0.462654\n",
      "Train Epoch: 138 [0/50000 (0%)]\tLoss: 0.347325\n",
      "Train Epoch: 138 [12800/50000 (26%)]\tLoss: 0.194195\n",
      "Train Epoch: 138 [25600/50000 (51%)]\tLoss: 0.389323\n",
      "Train Epoch: 138 [38400/50000 (77%)]\tLoss: 0.235631\n",
      "Train Epoch: 139 [0/50000 (0%)]\tLoss: 0.322431\n",
      "Train Epoch: 139 [12800/50000 (26%)]\tLoss: 0.547224\n",
      "Train Epoch: 139 [25600/50000 (51%)]\tLoss: 0.331466\n",
      "Train Epoch: 139 [38400/50000 (77%)]\tLoss: 0.324534\n",
      "Train Epoch: 140 [0/50000 (0%)]\tLoss: 0.359342\n",
      "Train Epoch: 140 [12800/50000 (26%)]\tLoss: 0.365807\n",
      "Train Epoch: 140 [25600/50000 (51%)]\tLoss: 0.386731\n",
      "Train Epoch: 140 [38400/50000 (77%)]\tLoss: 0.305567\n",
      "Train Epoch: 141 [0/50000 (0%)]\tLoss: 0.348846\n",
      "Train Epoch: 141 [12800/50000 (26%)]\tLoss: 0.381638\n",
      "Train Epoch: 141 [25600/50000 (51%)]\tLoss: 0.334107\n",
      "Train Epoch: 141 [38400/50000 (77%)]\tLoss: 0.347589\n",
      "Train Epoch: 142 [0/50000 (0%)]\tLoss: 0.339446\n",
      "Train Epoch: 142 [12800/50000 (26%)]\tLoss: 0.268119\n",
      "Train Epoch: 142 [25600/50000 (51%)]\tLoss: 0.496769\n",
      "Train Epoch: 142 [38400/50000 (77%)]\tLoss: 0.267875\n",
      "Train Epoch: 143 [0/50000 (0%)]\tLoss: 0.307774\n",
      "Train Epoch: 143 [12800/50000 (26%)]\tLoss: 0.546574\n",
      "Train Epoch: 143 [25600/50000 (51%)]\tLoss: 0.402183\n",
      "Train Epoch: 143 [38400/50000 (77%)]\tLoss: 0.355671\n",
      "Train Epoch: 144 [0/50000 (0%)]\tLoss: 0.279811\n",
      "Train Epoch: 144 [12800/50000 (26%)]\tLoss: 0.476042\n",
      "Train Epoch: 144 [25600/50000 (51%)]\tLoss: 0.371493\n",
      "Train Epoch: 144 [38400/50000 (77%)]\tLoss: 0.365939\n",
      "Train Epoch: 145 [0/50000 (0%)]\tLoss: 0.365468\n",
      "Train Epoch: 145 [12800/50000 (26%)]\tLoss: 0.336245\n",
      "Train Epoch: 145 [25600/50000 (51%)]\tLoss: 0.568359\n",
      "Train Epoch: 145 [38400/50000 (77%)]\tLoss: 0.344252\n",
      "Train Epoch: 146 [0/50000 (0%)]\tLoss: 0.466396\n",
      "Train Epoch: 146 [12800/50000 (26%)]\tLoss: 0.289171\n",
      "Train Epoch: 146 [25600/50000 (51%)]\tLoss: 0.386859\n",
      "Train Epoch: 146 [38400/50000 (77%)]\tLoss: 0.362176\n",
      "Train Epoch: 147 [0/50000 (0%)]\tLoss: 0.313273\n",
      "Train Epoch: 147 [12800/50000 (26%)]\tLoss: 0.287102\n",
      "Train Epoch: 147 [25600/50000 (51%)]\tLoss: 0.386580\n",
      "Train Epoch: 147 [38400/50000 (77%)]\tLoss: 0.372797\n",
      "Train Epoch: 148 [0/50000 (0%)]\tLoss: 0.607848\n",
      "Train Epoch: 148 [12800/50000 (26%)]\tLoss: 0.357924\n",
      "Train Epoch: 148 [25600/50000 (51%)]\tLoss: 0.334498\n",
      "Train Epoch: 148 [38400/50000 (77%)]\tLoss: 0.392942\n",
      "Train Epoch: 149 [0/50000 (0%)]\tLoss: 0.505131\n",
      "Train Epoch: 149 [12800/50000 (26%)]\tLoss: 0.368178\n",
      "Train Epoch: 149 [25600/50000 (51%)]\tLoss: 0.381379\n",
      "Train Epoch: 149 [38400/50000 (77%)]\tLoss: 0.451278\n",
      "Train Epoch: 150 [0/50000 (0%)]\tLoss: 0.378525\n",
      "Train Epoch: 150 [12800/50000 (26%)]\tLoss: 0.360708\n",
      "Train Epoch: 150 [25600/50000 (51%)]\tLoss: 0.399889\n",
      "Train Epoch: 150 [38400/50000 (77%)]\tLoss: 0.551696\n",
      "Train Epoch: 151 [0/50000 (0%)]\tLoss: 0.392593\n",
      "Train Epoch: 151 [12800/50000 (26%)]\tLoss: 0.316337\n",
      "Train Epoch: 151 [25600/50000 (51%)]\tLoss: 0.360253\n",
      "Train Epoch: 151 [38400/50000 (77%)]\tLoss: 0.321820\n",
      "Train Epoch: 152 [0/50000 (0%)]\tLoss: 0.402673\n",
      "Train Epoch: 152 [12800/50000 (26%)]\tLoss: 0.371683\n",
      "Train Epoch: 152 [25600/50000 (51%)]\tLoss: 0.386096\n",
      "Train Epoch: 152 [38400/50000 (77%)]\tLoss: 0.356940\n",
      "Train Epoch: 153 [0/50000 (0%)]\tLoss: 0.303347\n",
      "Train Epoch: 153 [12800/50000 (26%)]\tLoss: 0.386150\n",
      "Train Epoch: 153 [25600/50000 (51%)]\tLoss: 0.485050\n",
      "Train Epoch: 153 [38400/50000 (77%)]\tLoss: 0.434499\n",
      "Train Epoch: 154 [0/50000 (0%)]\tLoss: 0.273391\n",
      "Train Epoch: 154 [12800/50000 (26%)]\tLoss: 0.460627\n",
      "Train Epoch: 154 [25600/50000 (51%)]\tLoss: 0.494101\n",
      "Train Epoch: 154 [38400/50000 (77%)]\tLoss: 0.247923\n",
      "Train Epoch: 155 [0/50000 (0%)]\tLoss: 0.407566\n",
      "Train Epoch: 155 [12800/50000 (26%)]\tLoss: 0.453137\n",
      "Train Epoch: 155 [25600/50000 (51%)]\tLoss: 0.444727\n",
      "Train Epoch: 155 [38400/50000 (77%)]\tLoss: 0.408578\n",
      "Train Epoch: 156 [0/50000 (0%)]\tLoss: 0.500066\n",
      "Train Epoch: 156 [12800/50000 (26%)]\tLoss: 0.327626\n",
      "Train Epoch: 156 [25600/50000 (51%)]\tLoss: 0.295175\n",
      "Train Epoch: 156 [38400/50000 (77%)]\tLoss: 0.421113\n",
      "Train Epoch: 157 [0/50000 (0%)]\tLoss: 0.492002\n",
      "Train Epoch: 157 [12800/50000 (26%)]\tLoss: 0.419197\n",
      "Train Epoch: 157 [25600/50000 (51%)]\tLoss: 0.403610\n",
      "Train Epoch: 157 [38400/50000 (77%)]\tLoss: 0.428162\n",
      "Train Epoch: 158 [0/50000 (0%)]\tLoss: 0.391755\n",
      "Train Epoch: 158 [12800/50000 (26%)]\tLoss: 0.423582\n",
      "Train Epoch: 158 [25600/50000 (51%)]\tLoss: 0.428633\n",
      "Train Epoch: 158 [38400/50000 (77%)]\tLoss: 0.258243\n",
      "Train Epoch: 159 [0/50000 (0%)]\tLoss: 0.661210\n",
      "Train Epoch: 159 [12800/50000 (26%)]\tLoss: 0.342676\n",
      "Train Epoch: 159 [25600/50000 (51%)]\tLoss: 0.423354\n",
      "Train Epoch: 159 [38400/50000 (77%)]\tLoss: 0.363199\n",
      "Train Epoch: 160 [0/50000 (0%)]\tLoss: 0.443888\n",
      "Train Epoch: 160 [12800/50000 (26%)]\tLoss: 0.352384\n",
      "Train Epoch: 160 [25600/50000 (51%)]\tLoss: 0.490599\n",
      "Train Epoch: 160 [38400/50000 (77%)]\tLoss: 0.414984\n",
      "Train Epoch: 161 [0/50000 (0%)]\tLoss: 0.410196\n",
      "Train Epoch: 161 [12800/50000 (26%)]\tLoss: 0.339646\n",
      "Train Epoch: 161 [25600/50000 (51%)]\tLoss: 0.428003\n",
      "Train Epoch: 161 [38400/50000 (77%)]\tLoss: 0.241518\n",
      "Train Epoch: 162 [0/50000 (0%)]\tLoss: 0.458676\n",
      "Train Epoch: 162 [12800/50000 (26%)]\tLoss: 0.324895\n",
      "Train Epoch: 162 [25600/50000 (51%)]\tLoss: 0.362779\n",
      "Train Epoch: 162 [38400/50000 (77%)]\tLoss: 0.344545\n",
      "Train Epoch: 163 [0/50000 (0%)]\tLoss: 0.308039\n",
      "Train Epoch: 163 [12800/50000 (26%)]\tLoss: 0.403075\n",
      "Train Epoch: 163 [25600/50000 (51%)]\tLoss: 0.309713\n",
      "Train Epoch: 163 [38400/50000 (77%)]\tLoss: 0.406091\n",
      "Train Epoch: 164 [0/50000 (0%)]\tLoss: 0.459137\n",
      "Train Epoch: 164 [12800/50000 (26%)]\tLoss: 0.344749\n",
      "Train Epoch: 164 [25600/50000 (51%)]\tLoss: 0.413971\n",
      "Train Epoch: 164 [38400/50000 (77%)]\tLoss: 0.257066\n",
      "Train Epoch: 165 [0/50000 (0%)]\tLoss: 0.494857\n",
      "Train Epoch: 165 [12800/50000 (26%)]\tLoss: 0.425102\n",
      "Train Epoch: 165 [25600/50000 (51%)]\tLoss: 0.414279\n",
      "Train Epoch: 165 [38400/50000 (77%)]\tLoss: 0.309023\n",
      "Train Epoch: 166 [0/50000 (0%)]\tLoss: 0.421017\n",
      "Train Epoch: 166 [12800/50000 (26%)]\tLoss: 0.425705\n",
      "Train Epoch: 166 [25600/50000 (51%)]\tLoss: 0.349977\n",
      "Train Epoch: 166 [38400/50000 (77%)]\tLoss: 0.402828\n",
      "Train Epoch: 167 [0/50000 (0%)]\tLoss: 0.332798\n",
      "Train Epoch: 167 [12800/50000 (26%)]\tLoss: 0.361182\n",
      "Train Epoch: 167 [25600/50000 (51%)]\tLoss: 0.298517\n",
      "Train Epoch: 167 [38400/50000 (77%)]\tLoss: 0.366268\n",
      "Train Epoch: 168 [0/50000 (0%)]\tLoss: 0.484303\n",
      "Train Epoch: 168 [12800/50000 (26%)]\tLoss: 0.308061\n",
      "Train Epoch: 168 [25600/50000 (51%)]\tLoss: 0.361810\n",
      "Train Epoch: 168 [38400/50000 (77%)]\tLoss: 0.422417\n",
      "Train Epoch: 169 [0/50000 (0%)]\tLoss: 0.334703\n",
      "Train Epoch: 169 [12800/50000 (26%)]\tLoss: 0.342039\n",
      "Train Epoch: 169 [25600/50000 (51%)]\tLoss: 0.364009\n",
      "Train Epoch: 169 [38400/50000 (77%)]\tLoss: 0.463974\n",
      "Train Epoch: 170 [0/50000 (0%)]\tLoss: 0.309001\n",
      "Train Epoch: 170 [12800/50000 (26%)]\tLoss: 0.389997\n",
      "Train Epoch: 170 [25600/50000 (51%)]\tLoss: 0.351479\n",
      "Train Epoch: 170 [38400/50000 (77%)]\tLoss: 0.432925\n",
      "Train Epoch: 171 [0/50000 (0%)]\tLoss: 0.463520\n",
      "Train Epoch: 171 [12800/50000 (26%)]\tLoss: 0.424207\n",
      "Train Epoch: 171 [25600/50000 (51%)]\tLoss: 0.380208\n",
      "Train Epoch: 171 [38400/50000 (77%)]\tLoss: 0.371683\n",
      "Train Epoch: 172 [0/50000 (0%)]\tLoss: 0.342019\n",
      "Train Epoch: 172 [12800/50000 (26%)]\tLoss: 0.363475\n",
      "Train Epoch: 172 [25600/50000 (51%)]\tLoss: 0.339864\n",
      "Train Epoch: 172 [38400/50000 (77%)]\tLoss: 0.413558\n",
      "Train Epoch: 173 [0/50000 (0%)]\tLoss: 0.368795\n",
      "Train Epoch: 173 [12800/50000 (26%)]\tLoss: 0.365454\n",
      "Train Epoch: 173 [25600/50000 (51%)]\tLoss: 0.482972\n",
      "Train Epoch: 173 [38400/50000 (77%)]\tLoss: 0.204902\n",
      "Train Epoch: 174 [0/50000 (0%)]\tLoss: 0.367027\n",
      "Train Epoch: 174 [12800/50000 (26%)]\tLoss: 0.245690\n",
      "Train Epoch: 174 [25600/50000 (51%)]\tLoss: 0.558239\n",
      "Train Epoch: 174 [38400/50000 (77%)]\tLoss: 0.437222\n",
      "Train Epoch: 175 [0/50000 (0%)]\tLoss: 0.387203\n",
      "Train Epoch: 175 [12800/50000 (26%)]\tLoss: 0.310633\n",
      "Train Epoch: 175 [25600/50000 (51%)]\tLoss: 0.474782\n",
      "Train Epoch: 175 [38400/50000 (77%)]\tLoss: 0.430733\n",
      "Train Epoch: 176 [0/50000 (0%)]\tLoss: 0.388315\n",
      "Train Epoch: 176 [12800/50000 (26%)]\tLoss: 0.359345\n",
      "Train Epoch: 176 [25600/50000 (51%)]\tLoss: 0.515469\n",
      "Train Epoch: 176 [38400/50000 (77%)]\tLoss: 0.281803\n",
      "Train Epoch: 177 [0/50000 (0%)]\tLoss: 0.395128\n",
      "Train Epoch: 177 [12800/50000 (26%)]\tLoss: 0.438392\n",
      "Train Epoch: 177 [25600/50000 (51%)]\tLoss: 0.393613\n",
      "Train Epoch: 177 [38400/50000 (77%)]\tLoss: 0.263035\n",
      "Train Epoch: 178 [0/50000 (0%)]\tLoss: 0.324040\n",
      "Train Epoch: 178 [12800/50000 (26%)]\tLoss: 0.475242\n",
      "Train Epoch: 178 [25600/50000 (51%)]\tLoss: 0.474499\n",
      "Train Epoch: 178 [38400/50000 (77%)]\tLoss: 0.262917\n",
      "Train Epoch: 179 [0/50000 (0%)]\tLoss: 0.244683\n",
      "Train Epoch: 179 [12800/50000 (26%)]\tLoss: 0.456362\n",
      "Train Epoch: 179 [25600/50000 (51%)]\tLoss: 0.359273\n",
      "Train Epoch: 179 [38400/50000 (77%)]\tLoss: 0.420111\n",
      "Train Epoch: 180 [0/50000 (0%)]\tLoss: 0.303147\n",
      "Train Epoch: 180 [12800/50000 (26%)]\tLoss: 0.257833\n",
      "Train Epoch: 180 [25600/50000 (51%)]\tLoss: 0.562558\n",
      "Train Epoch: 180 [38400/50000 (77%)]\tLoss: 0.385198\n",
      "Train Epoch: 181 [0/50000 (0%)]\tLoss: 0.326068\n",
      "Train Epoch: 181 [12800/50000 (26%)]\tLoss: 0.404537\n",
      "Train Epoch: 181 [25600/50000 (51%)]\tLoss: 0.429030\n",
      "Train Epoch: 181 [38400/50000 (77%)]\tLoss: 0.389626\n",
      "Train Epoch: 182 [0/50000 (0%)]\tLoss: 0.396632\n",
      "Train Epoch: 182 [12800/50000 (26%)]\tLoss: 0.427956\n",
      "Train Epoch: 182 [25600/50000 (51%)]\tLoss: 0.293244\n",
      "Train Epoch: 182 [38400/50000 (77%)]\tLoss: 0.320215\n",
      "Train Epoch: 183 [0/50000 (0%)]\tLoss: 0.538464\n",
      "Train Epoch: 183 [12800/50000 (26%)]\tLoss: 0.392776\n",
      "Train Epoch: 183 [25600/50000 (51%)]\tLoss: 0.399153\n",
      "Train Epoch: 183 [38400/50000 (77%)]\tLoss: 0.382710\n",
      "Train Epoch: 184 [0/50000 (0%)]\tLoss: 0.411273\n",
      "Train Epoch: 184 [12800/50000 (26%)]\tLoss: 0.384476\n",
      "Train Epoch: 184 [25600/50000 (51%)]\tLoss: 0.328654\n",
      "Train Epoch: 184 [38400/50000 (77%)]\tLoss: 0.233084\n",
      "Train Epoch: 185 [0/50000 (0%)]\tLoss: 0.250516\n",
      "Train Epoch: 185 [12800/50000 (26%)]\tLoss: 0.361049\n",
      "Train Epoch: 185 [25600/50000 (51%)]\tLoss: 0.327294\n",
      "Train Epoch: 185 [38400/50000 (77%)]\tLoss: 0.275173\n",
      "Train Epoch: 186 [0/50000 (0%)]\tLoss: 0.282173\n",
      "Train Epoch: 186 [12800/50000 (26%)]\tLoss: 0.366782\n",
      "Train Epoch: 186 [25600/50000 (51%)]\tLoss: 0.331262\n",
      "Train Epoch: 186 [38400/50000 (77%)]\tLoss: 0.334896\n",
      "Train Epoch: 187 [0/50000 (0%)]\tLoss: 0.506254\n",
      "Train Epoch: 187 [12800/50000 (26%)]\tLoss: 0.391721\n",
      "Train Epoch: 187 [25600/50000 (51%)]\tLoss: 0.347312\n",
      "Train Epoch: 187 [38400/50000 (77%)]\tLoss: 0.432633\n",
      "Train Epoch: 188 [0/50000 (0%)]\tLoss: 0.274134\n",
      "Train Epoch: 188 [12800/50000 (26%)]\tLoss: 0.453485\n",
      "Train Epoch: 188 [25600/50000 (51%)]\tLoss: 0.518182\n",
      "Train Epoch: 188 [38400/50000 (77%)]\tLoss: 0.296646\n",
      "Train Epoch: 189 [0/50000 (0%)]\tLoss: 0.346616\n",
      "Train Epoch: 189 [12800/50000 (26%)]\tLoss: 0.336749\n",
      "Train Epoch: 189 [25600/50000 (51%)]\tLoss: 0.369872\n",
      "Train Epoch: 189 [38400/50000 (77%)]\tLoss: 0.283938\n",
      "Train Epoch: 190 [0/50000 (0%)]\tLoss: 0.284414\n",
      "Train Epoch: 190 [12800/50000 (26%)]\tLoss: 0.549880\n",
      "Train Epoch: 190 [25600/50000 (51%)]\tLoss: 0.330707\n",
      "Train Epoch: 190 [38400/50000 (77%)]\tLoss: 0.451397\n",
      "Train Epoch: 191 [0/50000 (0%)]\tLoss: 0.377390\n",
      "Train Epoch: 191 [12800/50000 (26%)]\tLoss: 0.341468\n",
      "Train Epoch: 191 [25600/50000 (51%)]\tLoss: 0.491009\n",
      "Train Epoch: 191 [38400/50000 (77%)]\tLoss: 0.403652\n",
      "Train Epoch: 192 [0/50000 (0%)]\tLoss: 0.383477\n",
      "Train Epoch: 192 [12800/50000 (26%)]\tLoss: 0.415870\n",
      "Train Epoch: 192 [25600/50000 (51%)]\tLoss: 0.434570\n",
      "Train Epoch: 192 [38400/50000 (77%)]\tLoss: 0.407778\n",
      "Train Epoch: 193 [0/50000 (0%)]\tLoss: 0.396578\n",
      "Train Epoch: 193 [12800/50000 (26%)]\tLoss: 0.364184\n",
      "Train Epoch: 193 [25600/50000 (51%)]\tLoss: 0.289766\n",
      "Train Epoch: 193 [38400/50000 (77%)]\tLoss: 0.290923\n",
      "Train Epoch: 194 [0/50000 (0%)]\tLoss: 0.339254\n",
      "Train Epoch: 194 [12800/50000 (26%)]\tLoss: 0.363664\n",
      "Train Epoch: 194 [25600/50000 (51%)]\tLoss: 0.470907\n",
      "Train Epoch: 194 [38400/50000 (77%)]\tLoss: 0.387163\n",
      "Train Epoch: 195 [0/50000 (0%)]\tLoss: 0.322110\n",
      "Train Epoch: 195 [12800/50000 (26%)]\tLoss: 0.390123\n",
      "Train Epoch: 195 [25600/50000 (51%)]\tLoss: 0.378421\n",
      "Train Epoch: 195 [38400/50000 (77%)]\tLoss: 0.321892\n",
      "Train Epoch: 196 [0/50000 (0%)]\tLoss: 0.389424\n",
      "Train Epoch: 196 [12800/50000 (26%)]\tLoss: 0.417335\n",
      "Train Epoch: 196 [25600/50000 (51%)]\tLoss: 0.352492\n",
      "Train Epoch: 196 [38400/50000 (77%)]\tLoss: 0.336678\n",
      "Train Epoch: 197 [0/50000 (0%)]\tLoss: 0.374773\n",
      "Train Epoch: 197 [12800/50000 (26%)]\tLoss: 0.424756\n",
      "Train Epoch: 197 [25600/50000 (51%)]\tLoss: 0.320640\n",
      "Train Epoch: 197 [38400/50000 (77%)]\tLoss: 0.505168\n",
      "Train Epoch: 198 [0/50000 (0%)]\tLoss: 0.480771\n",
      "Train Epoch: 198 [12800/50000 (26%)]\tLoss: 0.241388\n",
      "Train Epoch: 198 [25600/50000 (51%)]\tLoss: 0.473231\n",
      "Train Epoch: 198 [38400/50000 (77%)]\tLoss: 0.412858\n",
      "Train Epoch: 199 [0/50000 (0%)]\tLoss: 0.252406\n",
      "Train Epoch: 199 [12800/50000 (26%)]\tLoss: 0.418070\n",
      "Train Epoch: 199 [25600/50000 (51%)]\tLoss: 0.384218\n",
      "Train Epoch: 199 [38400/50000 (77%)]\tLoss: 0.379330\n",
      "Train Epoch: 200 [0/50000 (0%)]\tLoss: 0.280446\n",
      "Train Epoch: 200 [12800/50000 (26%)]\tLoss: 0.352163\n",
      "Train Epoch: 200 [25600/50000 (51%)]\tLoss: 0.384322\n",
      "Train Epoch: 200 [38400/50000 (77%)]\tLoss: 0.425446\n"
     ]
    }
   ],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "def train(model, device, trainloader, criterion, optimizer, epoch, writer, log_interval):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(trainloader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        writer.add_scalar('Train Loss', loss, (epoch - 1) * len(trainloader) + batch_idx)\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(trainloader.dataset),\n",
    "                100. * batch_idx / len(trainloader), loss.item()))\n",
    "\n",
    "# set the max training epoch and log_interval(for train loss printing interval)\n",
    "# initialize the writer\n",
    "epoch = 200\n",
    "log_interval = 100\n",
    "writer = SummaryWriter(log_dir='runs/CnnNet')\n",
    "\n",
    "# start train\n",
    "for epoch in range(1, epoch + 1):\n",
    "    train(model, device, trainloader, criterion, optimizer, epoch, writer, log_interval)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test the Trained Network\n",
    "\n",
    "Test your trained model on previously unseen data and print the test accuracy of each class and the whole! Try your best to get a better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8753/10000 (88%)\n",
      "\n",
      "\n",
      "Test set: Accuracy of airplane: 883.0/1000.0 (88%)\n",
      "\n",
      "\n",
      "Test set: Accuracy of automobile: 929.0/1000.0 (93%)\n",
      "\n",
      "\n",
      "Test set: Accuracy of bird : 790.0/1000.0 (79%)\n",
      "\n",
      "\n",
      "Test set: Accuracy of cat  : 740.0/1000.0 (74%)\n",
      "\n",
      "\n",
      "Test set: Accuracy of deer : 890.0/1000.0 (89%)\n",
      "\n",
      "\n",
      "Test set: Accuracy of dog  : 827.0/1000.0 (83%)\n",
      "\n",
      "\n",
      "Test set: Accuracy of frog : 946.0/1000.0 (95%)\n",
      "\n",
      "\n",
      "Test set: Accuracy of horse: 887.0/1000.0 (89%)\n",
      "\n",
      "\n",
      "Test set: Accuracy of ship : 933.0/1000.0 (93%)\n",
      "\n",
      "\n",
      "Test set: Accuracy of truck: 928.0/1000.0 (93%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test(model, device, testloader, criterion, epoch, writer):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    N_CLASSES = 10\n",
    "    class_correct = list(0. for i in range(N_CLASSES))\n",
    "    class_total = list(0. for i in range(N_CLASSES))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(testloader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "            \n",
    "            _, pred = output.max(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "\n",
    "            c = (pred == target).squeeze()\n",
    "            for i in range(len(target)):\n",
    "                _target = target[i]\n",
    "                class_correct[_target] += c[i].item()\n",
    "                class_total[_target] += 1\n",
    "\n",
    "\n",
    "    test_loss /= len(testloader.dataset)\n",
    "\n",
    "    # writer.add_scalar('Test Loss', test_loss, epoch - 1)\n",
    "    # writer.add_scalar('Test Accuracy', 100. * correct / len(testloader.dataset), epoch - 1)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))\n",
    "    \n",
    "    for i in range(N_CLASSES):\n",
    "        print('\\nTest set: Accuracy of {:5s}: {}/{} ({:.0f}%)\\n'.format(\n",
    "        classes[i], class_correct[i], class_total[i],\n",
    "        100. * class_correct[i] / (class_total[i]+1)))\n",
    "\n",
    "# start test\n",
    "test(model, device, testloader, criterion, epoch=200, writer=writer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# TASK_2: Resnet18\n",
    "---\n",
    "Since you have completed the simple convolutional neural networks, now we are going to construct a widely used model ResNet.\n",
    "In this task, we choose the **Resnet18** to classify images from the CIFAR-10 database.\n",
    "\n",
    "You are supposed to design the network architecture by yourself. DO NOT directly call the resent module 'torchvision.models.resnet' in pytorch.\n",
    "\n",
    "Now define the network and train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "\n",
    "device = torch.device(\"cuda\" if train_on_gpu else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# # To avoid ssl.SSLCertVerificationError\n",
    "# import ssl\n",
    "# ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "test output size:\n",
      " torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "# define the model ResNet-18\n",
    "model = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "print(model)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if train_on_gpu:\n",
    "    model.cuda()\n",
    "    device_ids = [0, 1, 2, 3, 4, 5]\n",
    "    model = nn.DataParallel(model, device_ids=device_ids)   #multigpu\n",
    "\n",
    "# test\n",
    "def test_ResNet18():\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "    y = model(torch.randn(10, 3, 32, 32))\n",
    "    print('test output size:\\n', y.size())\n",
    "test_ResNet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.535027\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.879644\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.589144\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.530121\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.602720\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.267005\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.367409\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.128361\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.069958\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 0.978888\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.906385\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.183850\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.932122\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 0.676753\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.860034\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 0.713821\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.570484\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.957704\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.614042\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.691579\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.510157\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.506522\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.586635\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.468309\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.533774\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.447471\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.487683\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.432278\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.512679\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.611283\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.503633\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.420062\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.523837\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.456175\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.380805\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.477432\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.470863\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.291539\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.335903\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.460526\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.343766\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 0.447258\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.376994\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 0.306812\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.319679\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 0.489859\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 0.347196\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 0.228750\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.354492\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 0.281289\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 0.355872\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 0.312442\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.244681\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 0.130587\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 0.251906\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 0.272485\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.268570\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 0.316101\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 0.222505\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 0.381135\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 0.310977\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 0.176208\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 0.191662\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 0.289939\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 0.237904\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 0.288063\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 0.190429\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 0.134883\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 0.218649\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 0.183541\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 0.203629\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 0.303744\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.258428\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 0.138590\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 0.229015\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 0.228987\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 0.113047\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 0.096906\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 0.317574\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 0.224135\n",
      "Train Epoch: 21 [0/50000 (0%)]\tLoss: 0.193072\n",
      "Train Epoch: 21 [12800/50000 (26%)]\tLoss: 0.158397\n",
      "Train Epoch: 21 [25600/50000 (51%)]\tLoss: 0.314462\n",
      "Train Epoch: 21 [38400/50000 (77%)]\tLoss: 0.164728\n",
      "Train Epoch: 22 [0/50000 (0%)]\tLoss: 0.179612\n",
      "Train Epoch: 22 [12800/50000 (26%)]\tLoss: 0.135692\n",
      "Train Epoch: 22 [25600/50000 (51%)]\tLoss: 0.171378\n",
      "Train Epoch: 22 [38400/50000 (77%)]\tLoss: 0.163442\n",
      "Train Epoch: 23 [0/50000 (0%)]\tLoss: 0.189003\n",
      "Train Epoch: 23 [12800/50000 (26%)]\tLoss: 0.102099\n",
      "Train Epoch: 23 [25600/50000 (51%)]\tLoss: 0.140675\n",
      "Train Epoch: 23 [38400/50000 (77%)]\tLoss: 0.203067\n",
      "Train Epoch: 24 [0/50000 (0%)]\tLoss: 0.156166\n",
      "Train Epoch: 24 [12800/50000 (26%)]\tLoss: 0.131320\n",
      "Train Epoch: 24 [25600/50000 (51%)]\tLoss: 0.262420\n",
      "Train Epoch: 24 [38400/50000 (77%)]\tLoss: 0.126646\n",
      "Train Epoch: 25 [0/50000 (0%)]\tLoss: 0.154966\n",
      "Train Epoch: 25 [12800/50000 (26%)]\tLoss: 0.207128\n",
      "Train Epoch: 25 [25600/50000 (51%)]\tLoss: 0.247442\n",
      "Train Epoch: 25 [38400/50000 (77%)]\tLoss: 0.119197\n",
      "Train Epoch: 26 [0/50000 (0%)]\tLoss: 0.236485\n",
      "Train Epoch: 26 [12800/50000 (26%)]\tLoss: 0.071761\n",
      "Train Epoch: 26 [25600/50000 (51%)]\tLoss: 0.154650\n",
      "Train Epoch: 26 [38400/50000 (77%)]\tLoss: 0.129892\n",
      "Train Epoch: 27 [0/50000 (0%)]\tLoss: 0.235179\n",
      "Train Epoch: 27 [12800/50000 (26%)]\tLoss: 0.118954\n",
      "Train Epoch: 27 [25600/50000 (51%)]\tLoss: 0.062686\n",
      "Train Epoch: 27 [38400/50000 (77%)]\tLoss: 0.160705\n",
      "Train Epoch: 28 [0/50000 (0%)]\tLoss: 0.114257\n",
      "Train Epoch: 28 [12800/50000 (26%)]\tLoss: 0.089313\n",
      "Train Epoch: 28 [25600/50000 (51%)]\tLoss: 0.063028\n",
      "Train Epoch: 28 [38400/50000 (77%)]\tLoss: 0.094698\n",
      "Train Epoch: 29 [0/50000 (0%)]\tLoss: 0.125221\n",
      "Train Epoch: 29 [12800/50000 (26%)]\tLoss: 0.144400\n",
      "Train Epoch: 29 [25600/50000 (51%)]\tLoss: 0.095952\n",
      "Train Epoch: 29 [38400/50000 (77%)]\tLoss: 0.129812\n",
      "Train Epoch: 30 [0/50000 (0%)]\tLoss: 0.153327\n",
      "Train Epoch: 30 [12800/50000 (26%)]\tLoss: 0.070422\n",
      "Train Epoch: 30 [25600/50000 (51%)]\tLoss: 0.110152\n",
      "Train Epoch: 30 [38400/50000 (77%)]\tLoss: 0.191493\n",
      "Train Epoch: 31 [0/50000 (0%)]\tLoss: 0.082969\n",
      "Train Epoch: 31 [12800/50000 (26%)]\tLoss: 0.108373\n",
      "Train Epoch: 31 [25600/50000 (51%)]\tLoss: 0.073209\n",
      "Train Epoch: 31 [38400/50000 (77%)]\tLoss: 0.065285\n",
      "Train Epoch: 32 [0/50000 (0%)]\tLoss: 0.059166\n",
      "Train Epoch: 32 [12800/50000 (26%)]\tLoss: 0.077693\n",
      "Train Epoch: 32 [25600/50000 (51%)]\tLoss: 0.166460\n",
      "Train Epoch: 32 [38400/50000 (77%)]\tLoss: 0.149476\n",
      "Train Epoch: 33 [0/50000 (0%)]\tLoss: 0.084372\n",
      "Train Epoch: 33 [12800/50000 (26%)]\tLoss: 0.277213\n",
      "Train Epoch: 33 [25600/50000 (51%)]\tLoss: 0.060775\n",
      "Train Epoch: 33 [38400/50000 (77%)]\tLoss: 0.096378\n",
      "Train Epoch: 34 [0/50000 (0%)]\tLoss: 0.059708\n",
      "Train Epoch: 34 [12800/50000 (26%)]\tLoss: 0.012815\n",
      "Train Epoch: 34 [25600/50000 (51%)]\tLoss: 0.084937\n",
      "Train Epoch: 34 [38400/50000 (77%)]\tLoss: 0.056875\n",
      "Train Epoch: 35 [0/50000 (0%)]\tLoss: 0.104062\n",
      "Train Epoch: 35 [12800/50000 (26%)]\tLoss: 0.030711\n",
      "Train Epoch: 35 [25600/50000 (51%)]\tLoss: 0.023412\n",
      "Train Epoch: 35 [38400/50000 (77%)]\tLoss: 0.035329\n",
      "Train Epoch: 36 [0/50000 (0%)]\tLoss: 0.031605\n",
      "Train Epoch: 36 [12800/50000 (26%)]\tLoss: 0.101159\n",
      "Train Epoch: 36 [25600/50000 (51%)]\tLoss: 0.062146\n",
      "Train Epoch: 36 [38400/50000 (77%)]\tLoss: 0.033907\n",
      "Train Epoch: 37 [0/50000 (0%)]\tLoss: 0.086074\n",
      "Train Epoch: 37 [12800/50000 (26%)]\tLoss: 0.108647\n",
      "Train Epoch: 37 [25600/50000 (51%)]\tLoss: 0.073957\n",
      "Train Epoch: 37 [38400/50000 (77%)]\tLoss: 0.069158\n",
      "Train Epoch: 38 [0/50000 (0%)]\tLoss: 0.059933\n",
      "Train Epoch: 38 [12800/50000 (26%)]\tLoss: 0.061525\n",
      "Train Epoch: 38 [25600/50000 (51%)]\tLoss: 0.065752\n",
      "Train Epoch: 38 [38400/50000 (77%)]\tLoss: 0.100928\n",
      "Train Epoch: 39 [0/50000 (0%)]\tLoss: 0.028290\n",
      "Train Epoch: 39 [12800/50000 (26%)]\tLoss: 0.056017\n",
      "Train Epoch: 39 [25600/50000 (51%)]\tLoss: 0.053545\n",
      "Train Epoch: 39 [38400/50000 (77%)]\tLoss: 0.028353\n",
      "Train Epoch: 40 [0/50000 (0%)]\tLoss: 0.030819\n",
      "Train Epoch: 40 [12800/50000 (26%)]\tLoss: 0.068093\n",
      "Train Epoch: 40 [25600/50000 (51%)]\tLoss: 0.040752\n",
      "Train Epoch: 40 [38400/50000 (77%)]\tLoss: 0.069992\n",
      "Train Epoch: 41 [0/50000 (0%)]\tLoss: 0.022422\n",
      "Train Epoch: 41 [12800/50000 (26%)]\tLoss: 0.033022\n",
      "Train Epoch: 41 [25600/50000 (51%)]\tLoss: 0.034933\n",
      "Train Epoch: 41 [38400/50000 (77%)]\tLoss: 0.025924\n",
      "Train Epoch: 42 [0/50000 (0%)]\tLoss: 0.019347\n",
      "Train Epoch: 42 [12800/50000 (26%)]\tLoss: 0.050108\n",
      "Train Epoch: 42 [25600/50000 (51%)]\tLoss: 0.105281\n",
      "Train Epoch: 42 [38400/50000 (77%)]\tLoss: 0.093191\n",
      "Train Epoch: 43 [0/50000 (0%)]\tLoss: 0.086814\n",
      "Train Epoch: 43 [12800/50000 (26%)]\tLoss: 0.075416\n",
      "Train Epoch: 43 [25600/50000 (51%)]\tLoss: 0.068584\n",
      "Train Epoch: 43 [38400/50000 (77%)]\tLoss: 0.077257\n",
      "Train Epoch: 44 [0/50000 (0%)]\tLoss: 0.066869\n",
      "Train Epoch: 44 [12800/50000 (26%)]\tLoss: 0.023909\n",
      "Train Epoch: 44 [25600/50000 (51%)]\tLoss: 0.041794\n",
      "Train Epoch: 44 [38400/50000 (77%)]\tLoss: 0.034073\n",
      "Train Epoch: 45 [0/50000 (0%)]\tLoss: 0.029792\n",
      "Train Epoch: 45 [12800/50000 (26%)]\tLoss: 0.047462\n",
      "Train Epoch: 45 [25600/50000 (51%)]\tLoss: 0.039075\n",
      "Train Epoch: 45 [38400/50000 (77%)]\tLoss: 0.034340\n",
      "Train Epoch: 46 [0/50000 (0%)]\tLoss: 0.018638\n",
      "Train Epoch: 46 [12800/50000 (26%)]\tLoss: 0.016501\n",
      "Train Epoch: 46 [25600/50000 (51%)]\tLoss: 0.012462\n",
      "Train Epoch: 46 [38400/50000 (77%)]\tLoss: 0.092632\n",
      "Train Epoch: 47 [0/50000 (0%)]\tLoss: 0.050962\n",
      "Train Epoch: 47 [12800/50000 (26%)]\tLoss: 0.019444\n",
      "Train Epoch: 47 [25600/50000 (51%)]\tLoss: 0.013958\n",
      "Train Epoch: 47 [38400/50000 (77%)]\tLoss: 0.046495\n",
      "Train Epoch: 48 [0/50000 (0%)]\tLoss: 0.036113\n",
      "Train Epoch: 48 [12800/50000 (26%)]\tLoss: 0.054109\n",
      "Train Epoch: 48 [25600/50000 (51%)]\tLoss: 0.026949\n",
      "Train Epoch: 48 [38400/50000 (77%)]\tLoss: 0.026461\n",
      "Train Epoch: 49 [0/50000 (0%)]\tLoss: 0.004710\n",
      "Train Epoch: 49 [12800/50000 (26%)]\tLoss: 0.035040\n",
      "Train Epoch: 49 [25600/50000 (51%)]\tLoss: 0.011810\n",
      "Train Epoch: 49 [38400/50000 (77%)]\tLoss: 0.003466\n",
      "Train Epoch: 50 [0/50000 (0%)]\tLoss: 0.036424\n",
      "Train Epoch: 50 [12800/50000 (26%)]\tLoss: 0.013490\n",
      "Train Epoch: 50 [25600/50000 (51%)]\tLoss: 0.008140\n",
      "Train Epoch: 50 [38400/50000 (77%)]\tLoss: 0.020053\n",
      "Train Epoch: 51 [0/50000 (0%)]\tLoss: 0.011104\n",
      "Train Epoch: 51 [12800/50000 (26%)]\tLoss: 0.013491\n",
      "Train Epoch: 51 [25600/50000 (51%)]\tLoss: 0.028901\n",
      "Train Epoch: 51 [38400/50000 (77%)]\tLoss: 0.009023\n",
      "Train Epoch: 52 [0/50000 (0%)]\tLoss: 0.134632\n",
      "Train Epoch: 52 [12800/50000 (26%)]\tLoss: 0.006613\n",
      "Train Epoch: 52 [25600/50000 (51%)]\tLoss: 0.102523\n",
      "Train Epoch: 52 [38400/50000 (77%)]\tLoss: 0.108214\n",
      "Train Epoch: 53 [0/50000 (0%)]\tLoss: 0.018656\n",
      "Train Epoch: 53 [12800/50000 (26%)]\tLoss: 0.030588\n",
      "Train Epoch: 53 [25600/50000 (51%)]\tLoss: 0.030018\n",
      "Train Epoch: 53 [38400/50000 (77%)]\tLoss: 0.022500\n",
      "Train Epoch: 54 [0/50000 (0%)]\tLoss: 0.025116\n",
      "Train Epoch: 54 [12800/50000 (26%)]\tLoss: 0.033556\n",
      "Train Epoch: 54 [25600/50000 (51%)]\tLoss: 0.009950\n",
      "Train Epoch: 54 [38400/50000 (77%)]\tLoss: 0.005247\n",
      "Train Epoch: 55 [0/50000 (0%)]\tLoss: 0.000740\n",
      "Train Epoch: 55 [12800/50000 (26%)]\tLoss: 0.004867\n",
      "Train Epoch: 55 [25600/50000 (51%)]\tLoss: 0.004788\n",
      "Train Epoch: 55 [38400/50000 (77%)]\tLoss: 0.016736\n",
      "Train Epoch: 56 [0/50000 (0%)]\tLoss: 0.005904\n",
      "Train Epoch: 56 [12800/50000 (26%)]\tLoss: 0.014504\n",
      "Train Epoch: 56 [25600/50000 (51%)]\tLoss: 0.015698\n",
      "Train Epoch: 56 [38400/50000 (77%)]\tLoss: 0.006994\n",
      "Train Epoch: 57 [0/50000 (0%)]\tLoss: 0.004207\n",
      "Train Epoch: 57 [12800/50000 (26%)]\tLoss: 0.063290\n",
      "Train Epoch: 57 [25600/50000 (51%)]\tLoss: 0.005969\n",
      "Train Epoch: 57 [38400/50000 (77%)]\tLoss: 0.030503\n",
      "Train Epoch: 58 [0/50000 (0%)]\tLoss: 0.008165\n",
      "Train Epoch: 58 [12800/50000 (26%)]\tLoss: 0.008149\n",
      "Train Epoch: 58 [25600/50000 (51%)]\tLoss: 0.018594\n",
      "Train Epoch: 58 [38400/50000 (77%)]\tLoss: 0.020960\n",
      "Train Epoch: 59 [0/50000 (0%)]\tLoss: 0.002193\n",
      "Train Epoch: 59 [12800/50000 (26%)]\tLoss: 0.043636\n",
      "Train Epoch: 59 [25600/50000 (51%)]\tLoss: 0.021629\n",
      "Train Epoch: 59 [38400/50000 (77%)]\tLoss: 0.028265\n",
      "Train Epoch: 60 [0/50000 (0%)]\tLoss: 0.051627\n",
      "Train Epoch: 60 [12800/50000 (26%)]\tLoss: 0.046880\n",
      "Train Epoch: 60 [25600/50000 (51%)]\tLoss: 0.020106\n",
      "Train Epoch: 60 [38400/50000 (77%)]\tLoss: 0.011759\n",
      "Train Epoch: 61 [0/50000 (0%)]\tLoss: 0.009219\n",
      "Train Epoch: 61 [12800/50000 (26%)]\tLoss: 0.004895\n",
      "Train Epoch: 61 [25600/50000 (51%)]\tLoss: 0.010473\n",
      "Train Epoch: 61 [38400/50000 (77%)]\tLoss: 0.003053\n",
      "Train Epoch: 62 [0/50000 (0%)]\tLoss: 0.009281\n",
      "Train Epoch: 62 [12800/50000 (26%)]\tLoss: 0.004509\n",
      "Train Epoch: 62 [25600/50000 (51%)]\tLoss: 0.007862\n",
      "Train Epoch: 62 [38400/50000 (77%)]\tLoss: 0.024166\n",
      "Train Epoch: 63 [0/50000 (0%)]\tLoss: 0.016980\n",
      "Train Epoch: 63 [12800/50000 (26%)]\tLoss: 0.039415\n",
      "Train Epoch: 63 [25600/50000 (51%)]\tLoss: 0.005336\n",
      "Train Epoch: 63 [38400/50000 (77%)]\tLoss: 0.001335\n",
      "Train Epoch: 64 [0/50000 (0%)]\tLoss: 0.008132\n",
      "Train Epoch: 64 [12800/50000 (26%)]\tLoss: 0.002965\n",
      "Train Epoch: 64 [25600/50000 (51%)]\tLoss: 0.065640\n",
      "Train Epoch: 64 [38400/50000 (77%)]\tLoss: 0.003939\n",
      "Train Epoch: 65 [0/50000 (0%)]\tLoss: 0.003982\n",
      "Train Epoch: 65 [12800/50000 (26%)]\tLoss: 0.005683\n",
      "Train Epoch: 65 [25600/50000 (51%)]\tLoss: 0.008425\n",
      "Train Epoch: 65 [38400/50000 (77%)]\tLoss: 0.005498\n",
      "Train Epoch: 66 [0/50000 (0%)]\tLoss: 0.008973\n",
      "Train Epoch: 66 [12800/50000 (26%)]\tLoss: 0.004736\n",
      "Train Epoch: 66 [25600/50000 (51%)]\tLoss: 0.001313\n",
      "Train Epoch: 66 [38400/50000 (77%)]\tLoss: 0.002084\n",
      "Train Epoch: 67 [0/50000 (0%)]\tLoss: 0.027061\n",
      "Train Epoch: 67 [12800/50000 (26%)]\tLoss: 0.011033\n",
      "Train Epoch: 67 [25600/50000 (51%)]\tLoss: 0.032499\n",
      "Train Epoch: 67 [38400/50000 (77%)]\tLoss: 0.030939\n",
      "Train Epoch: 68 [0/50000 (0%)]\tLoss: 0.021142\n",
      "Train Epoch: 68 [12800/50000 (26%)]\tLoss: 0.040433\n",
      "Train Epoch: 68 [25600/50000 (51%)]\tLoss: 0.002069\n",
      "Train Epoch: 68 [38400/50000 (77%)]\tLoss: 0.009425\n",
      "Train Epoch: 69 [0/50000 (0%)]\tLoss: 0.012917\n",
      "Train Epoch: 69 [12800/50000 (26%)]\tLoss: 0.001288\n",
      "Train Epoch: 69 [25600/50000 (51%)]\tLoss: 0.026805\n",
      "Train Epoch: 69 [38400/50000 (77%)]\tLoss: 0.004780\n",
      "Train Epoch: 70 [0/50000 (0%)]\tLoss: 0.001472\n",
      "Train Epoch: 70 [12800/50000 (26%)]\tLoss: 0.026447\n",
      "Train Epoch: 70 [25600/50000 (51%)]\tLoss: 0.013356\n",
      "Train Epoch: 70 [38400/50000 (77%)]\tLoss: 0.005213\n",
      "Train Epoch: 71 [0/50000 (0%)]\tLoss: 0.008053\n",
      "Train Epoch: 71 [12800/50000 (26%)]\tLoss: 0.018498\n",
      "Train Epoch: 71 [25600/50000 (51%)]\tLoss: 0.006677\n",
      "Train Epoch: 71 [38400/50000 (77%)]\tLoss: 0.003012\n",
      "Train Epoch: 72 [0/50000 (0%)]\tLoss: 0.005205\n",
      "Train Epoch: 72 [12800/50000 (26%)]\tLoss: 0.000685\n",
      "Train Epoch: 72 [25600/50000 (51%)]\tLoss: 0.002967\n",
      "Train Epoch: 72 [38400/50000 (77%)]\tLoss: 0.005725\n",
      "Train Epoch: 73 [0/50000 (0%)]\tLoss: 0.001639\n",
      "Train Epoch: 73 [12800/50000 (26%)]\tLoss: 0.015462\n",
      "Train Epoch: 73 [25600/50000 (51%)]\tLoss: 0.008402\n",
      "Train Epoch: 73 [38400/50000 (77%)]\tLoss: 0.034972\n",
      "Train Epoch: 74 [0/50000 (0%)]\tLoss: 0.032514\n",
      "Train Epoch: 74 [12800/50000 (26%)]\tLoss: 0.015057\n",
      "Train Epoch: 74 [25600/50000 (51%)]\tLoss: 0.019300\n",
      "Train Epoch: 74 [38400/50000 (77%)]\tLoss: 0.035119\n",
      "Train Epoch: 75 [0/50000 (0%)]\tLoss: 0.003209\n",
      "Train Epoch: 75 [12800/50000 (26%)]\tLoss: 0.016938\n",
      "Train Epoch: 75 [25600/50000 (51%)]\tLoss: 0.000609\n",
      "Train Epoch: 75 [38400/50000 (77%)]\tLoss: 0.002340\n",
      "Train Epoch: 76 [0/50000 (0%)]\tLoss: 0.001233\n",
      "Train Epoch: 76 [12800/50000 (26%)]\tLoss: 0.002517\n",
      "Train Epoch: 76 [25600/50000 (51%)]\tLoss: 0.011772\n",
      "Train Epoch: 76 [38400/50000 (77%)]\tLoss: 0.018804\n",
      "Train Epoch: 77 [0/50000 (0%)]\tLoss: 0.003286\n",
      "Train Epoch: 77 [12800/50000 (26%)]\tLoss: 0.001498\n",
      "Train Epoch: 77 [25600/50000 (51%)]\tLoss: 0.000589\n",
      "Train Epoch: 77 [38400/50000 (77%)]\tLoss: 0.000539\n",
      "Train Epoch: 78 [0/50000 (0%)]\tLoss: 0.003114\n",
      "Train Epoch: 78 [12800/50000 (26%)]\tLoss: 0.012534\n",
      "Train Epoch: 78 [25600/50000 (51%)]\tLoss: 0.007122\n",
      "Train Epoch: 78 [38400/50000 (77%)]\tLoss: 0.001683\n",
      "Train Epoch: 79 [0/50000 (0%)]\tLoss: 0.001400\n",
      "Train Epoch: 79 [12800/50000 (26%)]\tLoss: 0.002152\n",
      "Train Epoch: 79 [25600/50000 (51%)]\tLoss: 0.004272\n",
      "Train Epoch: 79 [38400/50000 (77%)]\tLoss: 0.001563\n",
      "Train Epoch: 80 [0/50000 (0%)]\tLoss: 0.000883\n",
      "Train Epoch: 80 [12800/50000 (26%)]\tLoss: 0.007500\n",
      "Train Epoch: 80 [25600/50000 (51%)]\tLoss: 0.013713\n",
      "Train Epoch: 80 [38400/50000 (77%)]\tLoss: 0.001997\n",
      "Train Epoch: 81 [0/50000 (0%)]\tLoss: 0.000577\n",
      "Train Epoch: 81 [12800/50000 (26%)]\tLoss: 0.032542\n",
      "Train Epoch: 81 [25600/50000 (51%)]\tLoss: 0.000791\n",
      "Train Epoch: 81 [38400/50000 (77%)]\tLoss: 0.001697\n",
      "Train Epoch: 82 [0/50000 (0%)]\tLoss: 0.002482\n",
      "Train Epoch: 82 [12800/50000 (26%)]\tLoss: 0.000774\n",
      "Train Epoch: 82 [25600/50000 (51%)]\tLoss: 0.001173\n",
      "Train Epoch: 82 [38400/50000 (77%)]\tLoss: 0.001776\n",
      "Train Epoch: 83 [0/50000 (0%)]\tLoss: 0.020148\n",
      "Train Epoch: 83 [12800/50000 (26%)]\tLoss: 0.004436\n",
      "Train Epoch: 83 [25600/50000 (51%)]\tLoss: 0.001364\n",
      "Train Epoch: 83 [38400/50000 (77%)]\tLoss: 0.000382\n",
      "Train Epoch: 84 [0/50000 (0%)]\tLoss: 0.000905\n",
      "Train Epoch: 84 [12800/50000 (26%)]\tLoss: 0.008086\n",
      "Train Epoch: 84 [25600/50000 (51%)]\tLoss: 0.002487\n",
      "Train Epoch: 84 [38400/50000 (77%)]\tLoss: 0.006402\n",
      "Train Epoch: 85 [0/50000 (0%)]\tLoss: 0.001132\n",
      "Train Epoch: 85 [12800/50000 (26%)]\tLoss: 0.010791\n",
      "Train Epoch: 85 [25600/50000 (51%)]\tLoss: 0.000884\n",
      "Train Epoch: 85 [38400/50000 (77%)]\tLoss: 0.000427\n",
      "Train Epoch: 86 [0/50000 (0%)]\tLoss: 0.002468\n",
      "Train Epoch: 86 [12800/50000 (26%)]\tLoss: 0.000468\n",
      "Train Epoch: 86 [25600/50000 (51%)]\tLoss: 0.002011\n",
      "Train Epoch: 86 [38400/50000 (77%)]\tLoss: 0.042814\n",
      "Train Epoch: 87 [0/50000 (0%)]\tLoss: 0.000696\n",
      "Train Epoch: 87 [12800/50000 (26%)]\tLoss: 0.024595\n",
      "Train Epoch: 87 [25600/50000 (51%)]\tLoss: 0.001576\n",
      "Train Epoch: 87 [38400/50000 (77%)]\tLoss: 0.000569\n",
      "Train Epoch: 88 [0/50000 (0%)]\tLoss: 0.002044\n",
      "Train Epoch: 88 [12800/50000 (26%)]\tLoss: 0.021629\n",
      "Train Epoch: 88 [25600/50000 (51%)]\tLoss: 0.015168\n",
      "Train Epoch: 88 [38400/50000 (77%)]\tLoss: 0.000185\n",
      "Train Epoch: 89 [0/50000 (0%)]\tLoss: 0.000283\n",
      "Train Epoch: 89 [12800/50000 (26%)]\tLoss: 0.013094\n",
      "Train Epoch: 89 [25600/50000 (51%)]\tLoss: 0.066855\n",
      "Train Epoch: 89 [38400/50000 (77%)]\tLoss: 0.000977\n",
      "Train Epoch: 90 [0/50000 (0%)]\tLoss: 0.002412\n",
      "Train Epoch: 90 [12800/50000 (26%)]\tLoss: 0.000273\n",
      "Train Epoch: 90 [25600/50000 (51%)]\tLoss: 0.028912\n",
      "Train Epoch: 90 [38400/50000 (77%)]\tLoss: 0.002637\n",
      "Train Epoch: 91 [0/50000 (0%)]\tLoss: 0.002286\n",
      "Train Epoch: 91 [12800/50000 (26%)]\tLoss: 0.003065\n",
      "Train Epoch: 91 [25600/50000 (51%)]\tLoss: 0.005616\n",
      "Train Epoch: 91 [38400/50000 (77%)]\tLoss: 0.000153\n",
      "Train Epoch: 92 [0/50000 (0%)]\tLoss: 0.006809\n",
      "Train Epoch: 92 [12800/50000 (26%)]\tLoss: 0.001869\n",
      "Train Epoch: 92 [25600/50000 (51%)]\tLoss: 0.000990\n",
      "Train Epoch: 92 [38400/50000 (77%)]\tLoss: 0.000330\n",
      "Train Epoch: 93 [0/50000 (0%)]\tLoss: 0.001568\n",
      "Train Epoch: 93 [12800/50000 (26%)]\tLoss: 0.008714\n",
      "Train Epoch: 93 [25600/50000 (51%)]\tLoss: 0.007117\n",
      "Train Epoch: 93 [38400/50000 (77%)]\tLoss: 0.001701\n",
      "Train Epoch: 94 [0/50000 (0%)]\tLoss: 0.001476\n",
      "Train Epoch: 94 [12800/50000 (26%)]\tLoss: 0.000342\n",
      "Train Epoch: 94 [25600/50000 (51%)]\tLoss: 0.000392\n",
      "Train Epoch: 94 [38400/50000 (77%)]\tLoss: 0.001093\n",
      "Train Epoch: 95 [0/50000 (0%)]\tLoss: 0.005063\n",
      "Train Epoch: 95 [12800/50000 (26%)]\tLoss: 0.033924\n",
      "Train Epoch: 95 [25600/50000 (51%)]\tLoss: 0.031758\n",
      "Train Epoch: 95 [38400/50000 (77%)]\tLoss: 0.000718\n",
      "Train Epoch: 96 [0/50000 (0%)]\tLoss: 0.005299\n",
      "Train Epoch: 96 [12800/50000 (26%)]\tLoss: 0.003761\n",
      "Train Epoch: 96 [25600/50000 (51%)]\tLoss: 0.004450\n",
      "Train Epoch: 96 [38400/50000 (77%)]\tLoss: 0.002232\n",
      "Train Epoch: 97 [0/50000 (0%)]\tLoss: 0.000926\n",
      "Train Epoch: 97 [12800/50000 (26%)]\tLoss: 0.000610\n",
      "Train Epoch: 97 [25600/50000 (51%)]\tLoss: 0.000335\n",
      "Train Epoch: 97 [38400/50000 (77%)]\tLoss: 0.000258\n",
      "Train Epoch: 98 [0/50000 (0%)]\tLoss: 0.007124\n",
      "Train Epoch: 98 [12800/50000 (26%)]\tLoss: 0.003369\n",
      "Train Epoch: 98 [25600/50000 (51%)]\tLoss: 0.003016\n",
      "Train Epoch: 98 [38400/50000 (77%)]\tLoss: 0.001277\n",
      "Train Epoch: 99 [0/50000 (0%)]\tLoss: 0.004781\n",
      "Train Epoch: 99 [12800/50000 (26%)]\tLoss: 0.000312\n",
      "Train Epoch: 99 [25600/50000 (51%)]\tLoss: 0.000458\n",
      "Train Epoch: 99 [38400/50000 (77%)]\tLoss: 0.000220\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 0.000277\n",
      "Train Epoch: 100 [12800/50000 (26%)]\tLoss: 0.000033\n",
      "Train Epoch: 100 [25600/50000 (51%)]\tLoss: 0.000665\n",
      "Train Epoch: 100 [38400/50000 (77%)]\tLoss: 0.009951\n",
      "Train Epoch: 101 [0/50000 (0%)]\tLoss: 0.000105\n",
      "Train Epoch: 101 [12800/50000 (26%)]\tLoss: 0.000216\n",
      "Train Epoch: 101 [25600/50000 (51%)]\tLoss: 0.000356\n",
      "Train Epoch: 101 [38400/50000 (77%)]\tLoss: 0.000712\n",
      "Train Epoch: 102 [0/50000 (0%)]\tLoss: 0.000038\n",
      "Train Epoch: 102 [12800/50000 (26%)]\tLoss: 0.000383\n",
      "Train Epoch: 102 [25600/50000 (51%)]\tLoss: 0.002119\n",
      "Train Epoch: 102 [38400/50000 (77%)]\tLoss: 0.000253\n",
      "Train Epoch: 103 [0/50000 (0%)]\tLoss: 0.000596\n",
      "Train Epoch: 103 [12800/50000 (26%)]\tLoss: 0.001276\n",
      "Train Epoch: 103 [25600/50000 (51%)]\tLoss: 0.005038\n",
      "Train Epoch: 103 [38400/50000 (77%)]\tLoss: 0.000060\n",
      "Train Epoch: 104 [0/50000 (0%)]\tLoss: 0.000080\n",
      "Train Epoch: 104 [12800/50000 (26%)]\tLoss: 0.009133\n",
      "Train Epoch: 104 [25600/50000 (51%)]\tLoss: 0.000373\n",
      "Train Epoch: 104 [38400/50000 (77%)]\tLoss: 0.000156\n",
      "Train Epoch: 105 [0/50000 (0%)]\tLoss: 0.000825\n",
      "Train Epoch: 105 [12800/50000 (26%)]\tLoss: 0.000610\n",
      "Train Epoch: 105 [25600/50000 (51%)]\tLoss: 0.000192\n",
      "Train Epoch: 105 [38400/50000 (77%)]\tLoss: 0.002363\n",
      "Train Epoch: 106 [0/50000 (0%)]\tLoss: 0.000178\n",
      "Train Epoch: 106 [12800/50000 (26%)]\tLoss: 0.000463\n",
      "Train Epoch: 106 [25600/50000 (51%)]\tLoss: 0.001463\n",
      "Train Epoch: 106 [38400/50000 (77%)]\tLoss: 0.000130\n",
      "Train Epoch: 107 [0/50000 (0%)]\tLoss: 0.000120\n",
      "Train Epoch: 107 [12800/50000 (26%)]\tLoss: 0.000161\n",
      "Train Epoch: 107 [25600/50000 (51%)]\tLoss: 0.004304\n",
      "Train Epoch: 107 [38400/50000 (77%)]\tLoss: 0.000232\n",
      "Train Epoch: 108 [0/50000 (0%)]\tLoss: 0.000500\n",
      "Train Epoch: 108 [12800/50000 (26%)]\tLoss: 0.015341\n",
      "Train Epoch: 108 [25600/50000 (51%)]\tLoss: 0.000044\n",
      "Train Epoch: 108 [38400/50000 (77%)]\tLoss: 0.002362\n",
      "Train Epoch: 109 [0/50000 (0%)]\tLoss: 0.000054\n",
      "Train Epoch: 109 [12800/50000 (26%)]\tLoss: 0.000994\n",
      "Train Epoch: 109 [25600/50000 (51%)]\tLoss: 0.000542\n",
      "Train Epoch: 109 [38400/50000 (77%)]\tLoss: 0.000345\n",
      "Train Epoch: 110 [0/50000 (0%)]\tLoss: 0.000748\n",
      "Train Epoch: 110 [12800/50000 (26%)]\tLoss: 0.032601\n",
      "Train Epoch: 110 [25600/50000 (51%)]\tLoss: 0.001868\n",
      "Train Epoch: 110 [38400/50000 (77%)]\tLoss: 0.000067\n",
      "Train Epoch: 111 [0/50000 (0%)]\tLoss: 0.008182\n",
      "Train Epoch: 111 [12800/50000 (26%)]\tLoss: 0.004307\n",
      "Train Epoch: 111 [25600/50000 (51%)]\tLoss: 0.009779\n",
      "Train Epoch: 111 [38400/50000 (77%)]\tLoss: 0.000434\n",
      "Train Epoch: 112 [0/50000 (0%)]\tLoss: 0.000596\n",
      "Train Epoch: 112 [12800/50000 (26%)]\tLoss: 0.000071\n",
      "Train Epoch: 112 [25600/50000 (51%)]\tLoss: 0.000009\n",
      "Train Epoch: 112 [38400/50000 (77%)]\tLoss: 0.000130\n",
      "Train Epoch: 113 [0/50000 (0%)]\tLoss: 0.000162\n",
      "Train Epoch: 113 [12800/50000 (26%)]\tLoss: 0.000600\n",
      "Train Epoch: 113 [25600/50000 (51%)]\tLoss: 0.000319\n",
      "Train Epoch: 113 [38400/50000 (77%)]\tLoss: 0.000941\n",
      "Train Epoch: 114 [0/50000 (0%)]\tLoss: 0.000263\n",
      "Train Epoch: 114 [12800/50000 (26%)]\tLoss: 0.000435\n",
      "Train Epoch: 114 [25600/50000 (51%)]\tLoss: 0.000126\n",
      "Train Epoch: 114 [38400/50000 (77%)]\tLoss: 0.000739\n",
      "Train Epoch: 115 [0/50000 (0%)]\tLoss: 0.000033\n",
      "Train Epoch: 115 [12800/50000 (26%)]\tLoss: 0.000308\n",
      "Train Epoch: 115 [25600/50000 (51%)]\tLoss: 0.000023\n",
      "Train Epoch: 115 [38400/50000 (77%)]\tLoss: 0.000259\n",
      "Train Epoch: 116 [0/50000 (0%)]\tLoss: 0.007105\n",
      "Train Epoch: 116 [12800/50000 (26%)]\tLoss: 0.000204\n",
      "Train Epoch: 116 [25600/50000 (51%)]\tLoss: 0.001636\n",
      "Train Epoch: 116 [38400/50000 (77%)]\tLoss: 0.000143\n",
      "Train Epoch: 117 [0/50000 (0%)]\tLoss: 0.000177\n",
      "Train Epoch: 117 [12800/50000 (26%)]\tLoss: 0.000459\n",
      "Train Epoch: 117 [25600/50000 (51%)]\tLoss: 0.000109\n",
      "Train Epoch: 117 [38400/50000 (77%)]\tLoss: 0.000146\n",
      "Train Epoch: 118 [0/50000 (0%)]\tLoss: 0.001474\n",
      "Train Epoch: 118 [12800/50000 (26%)]\tLoss: 0.000094\n",
      "Train Epoch: 118 [25600/50000 (51%)]\tLoss: 0.000012\n",
      "Train Epoch: 118 [38400/50000 (77%)]\tLoss: 0.000093\n",
      "Train Epoch: 119 [0/50000 (0%)]\tLoss: 0.000462\n",
      "Train Epoch: 119 [12800/50000 (26%)]\tLoss: 0.000237\n",
      "Train Epoch: 119 [25600/50000 (51%)]\tLoss: 0.001055\n",
      "Train Epoch: 119 [38400/50000 (77%)]\tLoss: 0.000123\n",
      "Train Epoch: 120 [0/50000 (0%)]\tLoss: 0.000167\n",
      "Train Epoch: 120 [12800/50000 (26%)]\tLoss: 0.000200\n",
      "Train Epoch: 120 [25600/50000 (51%)]\tLoss: 0.000072\n",
      "Train Epoch: 120 [38400/50000 (77%)]\tLoss: 0.000535\n",
      "Train Epoch: 121 [0/50000 (0%)]\tLoss: 0.002291\n",
      "Train Epoch: 121 [12800/50000 (26%)]\tLoss: 0.000193\n",
      "Train Epoch: 121 [25600/50000 (51%)]\tLoss: 0.000060\n",
      "Train Epoch: 121 [38400/50000 (77%)]\tLoss: 0.000079\n",
      "Train Epoch: 122 [0/50000 (0%)]\tLoss: 0.000100\n",
      "Train Epoch: 122 [12800/50000 (26%)]\tLoss: 0.000065\n",
      "Train Epoch: 122 [25600/50000 (51%)]\tLoss: 0.000375\n",
      "Train Epoch: 122 [38400/50000 (77%)]\tLoss: 0.000143\n",
      "Train Epoch: 123 [0/50000 (0%)]\tLoss: 0.000473\n",
      "Train Epoch: 123 [12800/50000 (26%)]\tLoss: 0.000092\n",
      "Train Epoch: 123 [25600/50000 (51%)]\tLoss: 0.000090\n",
      "Train Epoch: 123 [38400/50000 (77%)]\tLoss: 0.000010\n",
      "Train Epoch: 124 [0/50000 (0%)]\tLoss: 0.000096\n",
      "Train Epoch: 124 [12800/50000 (26%)]\tLoss: 0.000011\n",
      "Train Epoch: 124 [25600/50000 (51%)]\tLoss: 0.001122\n",
      "Train Epoch: 124 [38400/50000 (77%)]\tLoss: 0.000078\n",
      "Train Epoch: 125 [0/50000 (0%)]\tLoss: 0.000025\n",
      "Train Epoch: 125 [12800/50000 (26%)]\tLoss: 0.000661\n",
      "Train Epoch: 125 [25600/50000 (51%)]\tLoss: 0.000231\n",
      "Train Epoch: 125 [38400/50000 (77%)]\tLoss: 0.001186\n",
      "Train Epoch: 126 [0/50000 (0%)]\tLoss: 0.000027\n",
      "Train Epoch: 126 [12800/50000 (26%)]\tLoss: 0.000946\n",
      "Train Epoch: 126 [25600/50000 (51%)]\tLoss: 0.000008\n",
      "Train Epoch: 126 [38400/50000 (77%)]\tLoss: 0.000028\n",
      "Train Epoch: 127 [0/50000 (0%)]\tLoss: 0.000212\n",
      "Train Epoch: 127 [12800/50000 (26%)]\tLoss: 0.000121\n",
      "Train Epoch: 127 [25600/50000 (51%)]\tLoss: 0.000059\n",
      "Train Epoch: 127 [38400/50000 (77%)]\tLoss: 0.000197\n",
      "Train Epoch: 128 [0/50000 (0%)]\tLoss: 0.000165\n",
      "Train Epoch: 128 [12800/50000 (26%)]\tLoss: 0.000508\n",
      "Train Epoch: 128 [25600/50000 (51%)]\tLoss: 0.000578\n",
      "Train Epoch: 128 [38400/50000 (77%)]\tLoss: 0.001375\n",
      "Train Epoch: 129 [0/50000 (0%)]\tLoss: 0.001104\n",
      "Train Epoch: 129 [12800/50000 (26%)]\tLoss: 0.000036\n",
      "Train Epoch: 129 [25600/50000 (51%)]\tLoss: 0.000013\n",
      "Train Epoch: 129 [38400/50000 (77%)]\tLoss: 0.000018\n",
      "Train Epoch: 130 [0/50000 (0%)]\tLoss: 0.000105\n",
      "Train Epoch: 130 [12800/50000 (26%)]\tLoss: 0.000371\n",
      "Train Epoch: 130 [25600/50000 (51%)]\tLoss: 0.000057\n",
      "Train Epoch: 130 [38400/50000 (77%)]\tLoss: 0.000357\n",
      "Train Epoch: 131 [0/50000 (0%)]\tLoss: 0.001104\n",
      "Train Epoch: 131 [12800/50000 (26%)]\tLoss: 0.000023\n",
      "Train Epoch: 131 [25600/50000 (51%)]\tLoss: 0.001087\n",
      "Train Epoch: 131 [38400/50000 (77%)]\tLoss: 0.000088\n",
      "Train Epoch: 132 [0/50000 (0%)]\tLoss: 0.001209\n",
      "Train Epoch: 132 [12800/50000 (26%)]\tLoss: 0.001243\n",
      "Train Epoch: 132 [25600/50000 (51%)]\tLoss: 0.000051\n",
      "Train Epoch: 132 [38400/50000 (77%)]\tLoss: 0.000629\n",
      "Train Epoch: 133 [0/50000 (0%)]\tLoss: 0.000212\n",
      "Train Epoch: 133 [12800/50000 (26%)]\tLoss: 0.000046\n",
      "Train Epoch: 133 [25600/50000 (51%)]\tLoss: 0.000004\n",
      "Train Epoch: 133 [38400/50000 (77%)]\tLoss: 0.000032\n",
      "Train Epoch: 134 [0/50000 (0%)]\tLoss: 0.000425\n",
      "Train Epoch: 134 [12800/50000 (26%)]\tLoss: 0.000017\n",
      "Train Epoch: 134 [25600/50000 (51%)]\tLoss: 0.000070\n",
      "Train Epoch: 134 [38400/50000 (77%)]\tLoss: 0.000137\n",
      "Train Epoch: 135 [0/50000 (0%)]\tLoss: 0.000058\n",
      "Train Epoch: 135 [12800/50000 (26%)]\tLoss: 0.000032\n",
      "Train Epoch: 135 [25600/50000 (51%)]\tLoss: 0.000016\n",
      "Train Epoch: 135 [38400/50000 (77%)]\tLoss: 0.000018\n",
      "Train Epoch: 136 [0/50000 (0%)]\tLoss: 0.000014\n",
      "Train Epoch: 136 [12800/50000 (26%)]\tLoss: 0.006565\n",
      "Train Epoch: 136 [25600/50000 (51%)]\tLoss: 0.000018\n",
      "Train Epoch: 136 [38400/50000 (77%)]\tLoss: 0.048482\n",
      "Train Epoch: 137 [0/50000 (0%)]\tLoss: 0.000023\n",
      "Train Epoch: 137 [12800/50000 (26%)]\tLoss: 0.000073\n",
      "Train Epoch: 137 [25600/50000 (51%)]\tLoss: 0.000029\n",
      "Train Epoch: 137 [38400/50000 (77%)]\tLoss: 0.002173\n",
      "Train Epoch: 138 [0/50000 (0%)]\tLoss: 0.000693\n",
      "Train Epoch: 138 [12800/50000 (26%)]\tLoss: 0.000114\n",
      "Train Epoch: 138 [25600/50000 (51%)]\tLoss: 0.000089\n",
      "Train Epoch: 138 [38400/50000 (77%)]\tLoss: 0.000026\n",
      "Train Epoch: 139 [0/50000 (0%)]\tLoss: 0.000092\n",
      "Train Epoch: 139 [12800/50000 (26%)]\tLoss: 0.000079\n",
      "Train Epoch: 139 [25600/50000 (51%)]\tLoss: 0.000031\n",
      "Train Epoch: 139 [38400/50000 (77%)]\tLoss: 0.000236\n",
      "Train Epoch: 140 [0/50000 (0%)]\tLoss: 0.000214\n",
      "Train Epoch: 140 [12800/50000 (26%)]\tLoss: 0.000037\n",
      "Train Epoch: 140 [25600/50000 (51%)]\tLoss: 0.000002\n",
      "Train Epoch: 140 [38400/50000 (77%)]\tLoss: 0.000058\n",
      "Train Epoch: 141 [0/50000 (0%)]\tLoss: 0.000275\n",
      "Train Epoch: 141 [12800/50000 (26%)]\tLoss: 0.000006\n",
      "Train Epoch: 141 [25600/50000 (51%)]\tLoss: 0.000094\n",
      "Train Epoch: 141 [38400/50000 (77%)]\tLoss: 0.000042\n",
      "Train Epoch: 142 [0/50000 (0%)]\tLoss: 0.008506\n",
      "Train Epoch: 142 [12800/50000 (26%)]\tLoss: 0.000057\n",
      "Train Epoch: 142 [25600/50000 (51%)]\tLoss: 0.000023\n",
      "Train Epoch: 142 [38400/50000 (77%)]\tLoss: 0.000021\n",
      "Train Epoch: 143 [0/50000 (0%)]\tLoss: 0.000046\n",
      "Train Epoch: 143 [12800/50000 (26%)]\tLoss: 0.000659\n",
      "Train Epoch: 143 [25600/50000 (51%)]\tLoss: 0.000012\n",
      "Train Epoch: 143 [38400/50000 (77%)]\tLoss: 0.000073\n",
      "Train Epoch: 144 [0/50000 (0%)]\tLoss: 0.000196\n",
      "Train Epoch: 144 [12800/50000 (26%)]\tLoss: 0.000068\n",
      "Train Epoch: 144 [25600/50000 (51%)]\tLoss: 0.000067\n",
      "Train Epoch: 144 [38400/50000 (77%)]\tLoss: 0.000085\n",
      "Train Epoch: 145 [0/50000 (0%)]\tLoss: 0.000106\n",
      "Train Epoch: 145 [12800/50000 (26%)]\tLoss: 0.000316\n",
      "Train Epoch: 145 [25600/50000 (51%)]\tLoss: 0.000285\n",
      "Train Epoch: 145 [38400/50000 (77%)]\tLoss: 0.000084\n",
      "Train Epoch: 146 [0/50000 (0%)]\tLoss: 0.000147\n",
      "Train Epoch: 146 [12800/50000 (26%)]\tLoss: 0.000028\n",
      "Train Epoch: 146 [25600/50000 (51%)]\tLoss: 0.000027\n",
      "Train Epoch: 146 [38400/50000 (77%)]\tLoss: 0.000101\n",
      "Train Epoch: 147 [0/50000 (0%)]\tLoss: 0.000084\n",
      "Train Epoch: 147 [12800/50000 (26%)]\tLoss: 0.000078\n",
      "Train Epoch: 147 [25600/50000 (51%)]\tLoss: 0.000981\n",
      "Train Epoch: 147 [38400/50000 (77%)]\tLoss: 0.000141\n",
      "Train Epoch: 148 [0/50000 (0%)]\tLoss: 0.000019\n",
      "Train Epoch: 148 [12800/50000 (26%)]\tLoss: 0.000048\n",
      "Train Epoch: 148 [25600/50000 (51%)]\tLoss: 0.000063\n",
      "Train Epoch: 148 [38400/50000 (77%)]\tLoss: 0.000373\n",
      "Train Epoch: 149 [0/50000 (0%)]\tLoss: 0.000033\n",
      "Train Epoch: 149 [12800/50000 (26%)]\tLoss: 0.000278\n",
      "Train Epoch: 149 [25600/50000 (51%)]\tLoss: 0.000065\n",
      "Train Epoch: 149 [38400/50000 (77%)]\tLoss: 0.000095\n",
      "Train Epoch: 150 [0/50000 (0%)]\tLoss: 0.000051\n",
      "Train Epoch: 150 [12800/50000 (26%)]\tLoss: 0.000387\n",
      "Train Epoch: 150 [25600/50000 (51%)]\tLoss: 0.000076\n",
      "Train Epoch: 150 [38400/50000 (77%)]\tLoss: 0.000049\n",
      "Train Epoch: 151 [0/50000 (0%)]\tLoss: 0.000027\n",
      "Train Epoch: 151 [12800/50000 (26%)]\tLoss: 0.000117\n",
      "Train Epoch: 151 [25600/50000 (51%)]\tLoss: 0.000032\n",
      "Train Epoch: 151 [38400/50000 (77%)]\tLoss: 0.000126\n",
      "Train Epoch: 152 [0/50000 (0%)]\tLoss: 0.000008\n",
      "Train Epoch: 152 [12800/50000 (26%)]\tLoss: 0.000023\n",
      "Train Epoch: 152 [25600/50000 (51%)]\tLoss: 0.000088\n",
      "Train Epoch: 152 [38400/50000 (77%)]\tLoss: 0.000047\n",
      "Train Epoch: 153 [0/50000 (0%)]\tLoss: 0.000026\n",
      "Train Epoch: 153 [12800/50000 (26%)]\tLoss: 0.000321\n",
      "Train Epoch: 153 [25600/50000 (51%)]\tLoss: 0.000148\n",
      "Train Epoch: 153 [38400/50000 (77%)]\tLoss: 0.000026\n",
      "Train Epoch: 154 [0/50000 (0%)]\tLoss: 0.000027\n",
      "Train Epoch: 154 [12800/50000 (26%)]\tLoss: 0.000022\n",
      "Train Epoch: 154 [25600/50000 (51%)]\tLoss: 0.000060\n",
      "Train Epoch: 154 [38400/50000 (77%)]\tLoss: 0.000216\n",
      "Train Epoch: 155 [0/50000 (0%)]\tLoss: 0.000056\n",
      "Train Epoch: 155 [12800/50000 (26%)]\tLoss: 0.000015\n",
      "Train Epoch: 155 [25600/50000 (51%)]\tLoss: 0.000072\n",
      "Train Epoch: 155 [38400/50000 (77%)]\tLoss: 0.000019\n",
      "Train Epoch: 156 [0/50000 (0%)]\tLoss: 0.000020\n",
      "Train Epoch: 156 [12800/50000 (26%)]\tLoss: 0.000028\n",
      "Train Epoch: 156 [25600/50000 (51%)]\tLoss: 0.001526\n",
      "Train Epoch: 156 [38400/50000 (77%)]\tLoss: 0.000005\n",
      "Train Epoch: 157 [0/50000 (0%)]\tLoss: 0.000061\n",
      "Train Epoch: 157 [12800/50000 (26%)]\tLoss: 0.000050\n",
      "Train Epoch: 157 [25600/50000 (51%)]\tLoss: 0.000062\n",
      "Train Epoch: 157 [38400/50000 (77%)]\tLoss: 0.000149\n",
      "Train Epoch: 158 [0/50000 (0%)]\tLoss: 0.000013\n",
      "Train Epoch: 158 [12800/50000 (26%)]\tLoss: 0.000107\n",
      "Train Epoch: 158 [25600/50000 (51%)]\tLoss: 0.000028\n",
      "Train Epoch: 158 [38400/50000 (77%)]\tLoss: 0.000010\n",
      "Train Epoch: 159 [0/50000 (0%)]\tLoss: 0.000283\n",
      "Train Epoch: 159 [12800/50000 (26%)]\tLoss: 0.000042\n",
      "Train Epoch: 159 [25600/50000 (51%)]\tLoss: 0.000614\n",
      "Train Epoch: 159 [38400/50000 (77%)]\tLoss: 0.000056\n",
      "Train Epoch: 160 [0/50000 (0%)]\tLoss: 0.000042\n",
      "Train Epoch: 160 [12800/50000 (26%)]\tLoss: 0.000008\n",
      "Train Epoch: 160 [25600/50000 (51%)]\tLoss: 0.000006\n",
      "Train Epoch: 160 [38400/50000 (77%)]\tLoss: 0.000258\n",
      "Train Epoch: 161 [0/50000 (0%)]\tLoss: 0.000027\n",
      "Train Epoch: 161 [12800/50000 (26%)]\tLoss: 0.000084\n",
      "Train Epoch: 161 [25600/50000 (51%)]\tLoss: 0.000084\n",
      "Train Epoch: 161 [38400/50000 (77%)]\tLoss: 0.000018\n",
      "Train Epoch: 162 [0/50000 (0%)]\tLoss: 0.000049\n",
      "Train Epoch: 162 [12800/50000 (26%)]\tLoss: 0.000115\n",
      "Train Epoch: 162 [25600/50000 (51%)]\tLoss: 0.000013\n",
      "Train Epoch: 162 [38400/50000 (77%)]\tLoss: 0.000157\n",
      "Train Epoch: 163 [0/50000 (0%)]\tLoss: 0.000006\n",
      "Train Epoch: 163 [12800/50000 (26%)]\tLoss: 0.000081\n",
      "Train Epoch: 163 [25600/50000 (51%)]\tLoss: 0.000075\n",
      "Train Epoch: 163 [38400/50000 (77%)]\tLoss: 0.000015\n",
      "Train Epoch: 164 [0/50000 (0%)]\tLoss: 0.000003\n",
      "Train Epoch: 164 [12800/50000 (26%)]\tLoss: 0.000052\n",
      "Train Epoch: 164 [25600/50000 (51%)]\tLoss: 0.000073\n",
      "Train Epoch: 164 [38400/50000 (77%)]\tLoss: 0.000133\n",
      "Train Epoch: 165 [0/50000 (0%)]\tLoss: 0.000084\n",
      "Train Epoch: 165 [12800/50000 (26%)]\tLoss: 0.000037\n",
      "Train Epoch: 165 [25600/50000 (51%)]\tLoss: 0.000043\n",
      "Train Epoch: 165 [38400/50000 (77%)]\tLoss: 0.000016\n",
      "Train Epoch: 166 [0/50000 (0%)]\tLoss: 0.000057\n",
      "Train Epoch: 166 [12800/50000 (26%)]\tLoss: 0.000108\n",
      "Train Epoch: 166 [25600/50000 (51%)]\tLoss: 0.000050\n",
      "Train Epoch: 166 [38400/50000 (77%)]\tLoss: 0.000006\n",
      "Train Epoch: 167 [0/50000 (0%)]\tLoss: 0.000004\n",
      "Train Epoch: 167 [12800/50000 (26%)]\tLoss: 0.000362\n",
      "Train Epoch: 167 [25600/50000 (51%)]\tLoss: 0.000026\n",
      "Train Epoch: 167 [38400/50000 (77%)]\tLoss: 0.002451\n",
      "Train Epoch: 168 [0/50000 (0%)]\tLoss: 0.000029\n",
      "Train Epoch: 168 [12800/50000 (26%)]\tLoss: 0.000064\n",
      "Train Epoch: 168 [25600/50000 (51%)]\tLoss: 0.000027\n",
      "Train Epoch: 168 [38400/50000 (77%)]\tLoss: 0.000435\n",
      "Train Epoch: 169 [0/50000 (0%)]\tLoss: 0.001621\n",
      "Train Epoch: 169 [12800/50000 (26%)]\tLoss: 0.000009\n",
      "Train Epoch: 169 [25600/50000 (51%)]\tLoss: 0.000166\n",
      "Train Epoch: 169 [38400/50000 (77%)]\tLoss: 0.000111\n",
      "Train Epoch: 170 [0/50000 (0%)]\tLoss: 0.000032\n",
      "Train Epoch: 170 [12800/50000 (26%)]\tLoss: 0.000058\n",
      "Train Epoch: 170 [25600/50000 (51%)]\tLoss: 0.000120\n",
      "Train Epoch: 170 [38400/50000 (77%)]\tLoss: 0.000109\n",
      "Train Epoch: 171 [0/50000 (0%)]\tLoss: 0.000042\n",
      "Train Epoch: 171 [12800/50000 (26%)]\tLoss: 0.000027\n",
      "Train Epoch: 171 [25600/50000 (51%)]\tLoss: 0.000024\n",
      "Train Epoch: 171 [38400/50000 (77%)]\tLoss: 0.000028\n",
      "Train Epoch: 172 [0/50000 (0%)]\tLoss: 0.000018\n",
      "Train Epoch: 172 [12800/50000 (26%)]\tLoss: 0.000011\n",
      "Train Epoch: 172 [25600/50000 (51%)]\tLoss: 0.000021\n",
      "Train Epoch: 172 [38400/50000 (77%)]\tLoss: 0.000067\n",
      "Train Epoch: 173 [0/50000 (0%)]\tLoss: 0.000928\n",
      "Train Epoch: 173 [12800/50000 (26%)]\tLoss: 0.000201\n",
      "Train Epoch: 173 [25600/50000 (51%)]\tLoss: 0.000061\n",
      "Train Epoch: 173 [38400/50000 (77%)]\tLoss: 0.000087\n",
      "Train Epoch: 174 [0/50000 (0%)]\tLoss: 0.000010\n",
      "Train Epoch: 174 [12800/50000 (26%)]\tLoss: 0.000076\n",
      "Train Epoch: 174 [25600/50000 (51%)]\tLoss: 0.000058\n",
      "Train Epoch: 174 [38400/50000 (77%)]\tLoss: 0.000011\n",
      "Train Epoch: 175 [0/50000 (0%)]\tLoss: 0.000006\n",
      "Train Epoch: 175 [12800/50000 (26%)]\tLoss: 0.000007\n",
      "Train Epoch: 175 [25600/50000 (51%)]\tLoss: 0.000035\n",
      "Train Epoch: 175 [38400/50000 (77%)]\tLoss: 0.001003\n",
      "Train Epoch: 176 [0/50000 (0%)]\tLoss: 0.000010\n",
      "Train Epoch: 176 [12800/50000 (26%)]\tLoss: 0.000065\n",
      "Train Epoch: 176 [25600/50000 (51%)]\tLoss: 0.000796\n",
      "Train Epoch: 176 [38400/50000 (77%)]\tLoss: 0.000020\n",
      "Train Epoch: 177 [0/50000 (0%)]\tLoss: 0.000025\n",
      "Train Epoch: 177 [12800/50000 (26%)]\tLoss: 0.000050\n",
      "Train Epoch: 177 [25600/50000 (51%)]\tLoss: 0.000535\n",
      "Train Epoch: 177 [38400/50000 (77%)]\tLoss: 0.000022\n",
      "Train Epoch: 178 [0/50000 (0%)]\tLoss: 0.000077\n",
      "Train Epoch: 178 [12800/50000 (26%)]\tLoss: 0.001186\n",
      "Train Epoch: 178 [25600/50000 (51%)]\tLoss: 0.000025\n",
      "Train Epoch: 178 [38400/50000 (77%)]\tLoss: 0.000053\n",
      "Train Epoch: 179 [0/50000 (0%)]\tLoss: 0.000015\n",
      "Train Epoch: 179 [12800/50000 (26%)]\tLoss: 0.000041\n",
      "Train Epoch: 179 [25600/50000 (51%)]\tLoss: 0.000003\n",
      "Train Epoch: 179 [38400/50000 (77%)]\tLoss: 0.000096\n",
      "Train Epoch: 180 [0/50000 (0%)]\tLoss: 0.000020\n",
      "Train Epoch: 180 [12800/50000 (26%)]\tLoss: 0.000883\n",
      "Train Epoch: 180 [25600/50000 (51%)]\tLoss: 0.000124\n",
      "Train Epoch: 180 [38400/50000 (77%)]\tLoss: 0.000071\n",
      "Train Epoch: 181 [0/50000 (0%)]\tLoss: 0.000108\n",
      "Train Epoch: 181 [12800/50000 (26%)]\tLoss: 0.000193\n",
      "Train Epoch: 181 [25600/50000 (51%)]\tLoss: 0.000075\n",
      "Train Epoch: 181 [38400/50000 (77%)]\tLoss: 0.000331\n",
      "Train Epoch: 182 [0/50000 (0%)]\tLoss: 0.000530\n",
      "Train Epoch: 182 [12800/50000 (26%)]\tLoss: 0.000017\n",
      "Train Epoch: 182 [25600/50000 (51%)]\tLoss: 0.000446\n",
      "Train Epoch: 182 [38400/50000 (77%)]\tLoss: 0.000026\n",
      "Train Epoch: 183 [0/50000 (0%)]\tLoss: 0.000015\n",
      "Train Epoch: 183 [12800/50000 (26%)]\tLoss: 0.000150\n",
      "Train Epoch: 183 [25600/50000 (51%)]\tLoss: 0.000086\n",
      "Train Epoch: 183 [38400/50000 (77%)]\tLoss: 0.000475\n",
      "Train Epoch: 184 [0/50000 (0%)]\tLoss: 0.000017\n",
      "Train Epoch: 184 [12800/50000 (26%)]\tLoss: 0.000507\n",
      "Train Epoch: 184 [25600/50000 (51%)]\tLoss: 0.000012\n",
      "Train Epoch: 184 [38400/50000 (77%)]\tLoss: 0.000151\n",
      "Train Epoch: 185 [0/50000 (0%)]\tLoss: 0.000013\n",
      "Train Epoch: 185 [12800/50000 (26%)]\tLoss: 0.000036\n",
      "Train Epoch: 185 [25600/50000 (51%)]\tLoss: 0.000096\n",
      "Train Epoch: 185 [38400/50000 (77%)]\tLoss: 0.000253\n",
      "Train Epoch: 186 [0/50000 (0%)]\tLoss: 0.000043\n",
      "Train Epoch: 186 [12800/50000 (26%)]\tLoss: 0.000019\n",
      "Train Epoch: 186 [25600/50000 (51%)]\tLoss: 0.002094\n",
      "Train Epoch: 186 [38400/50000 (77%)]\tLoss: 0.002023\n",
      "Train Epoch: 187 [0/50000 (0%)]\tLoss: 0.000056\n",
      "Train Epoch: 187 [12800/50000 (26%)]\tLoss: 0.000118\n",
      "Train Epoch: 187 [25600/50000 (51%)]\tLoss: 0.000006\n",
      "Train Epoch: 187 [38400/50000 (77%)]\tLoss: 0.000003\n",
      "Train Epoch: 188 [0/50000 (0%)]\tLoss: 0.000724\n",
      "Train Epoch: 188 [12800/50000 (26%)]\tLoss: 0.004279\n",
      "Train Epoch: 188 [25600/50000 (51%)]\tLoss: 0.000022\n",
      "Train Epoch: 188 [38400/50000 (77%)]\tLoss: 0.000057\n",
      "Train Epoch: 189 [0/50000 (0%)]\tLoss: 0.000032\n",
      "Train Epoch: 189 [12800/50000 (26%)]\tLoss: 0.000107\n",
      "Train Epoch: 189 [25600/50000 (51%)]\tLoss: 0.000012\n",
      "Train Epoch: 189 [38400/50000 (77%)]\tLoss: 0.000052\n",
      "Train Epoch: 190 [0/50000 (0%)]\tLoss: 0.000606\n",
      "Train Epoch: 190 [12800/50000 (26%)]\tLoss: 0.000027\n",
      "Train Epoch: 190 [25600/50000 (51%)]\tLoss: 0.000045\n",
      "Train Epoch: 190 [38400/50000 (77%)]\tLoss: 0.000193\n",
      "Train Epoch: 191 [0/50000 (0%)]\tLoss: 0.000015\n",
      "Train Epoch: 191 [12800/50000 (26%)]\tLoss: 0.000069\n",
      "Train Epoch: 191 [25600/50000 (51%)]\tLoss: 0.000050\n",
      "Train Epoch: 191 [38400/50000 (77%)]\tLoss: 0.000048\n",
      "Train Epoch: 192 [0/50000 (0%)]\tLoss: 0.000110\n",
      "Train Epoch: 192 [12800/50000 (26%)]\tLoss: 0.002397\n",
      "Train Epoch: 192 [25600/50000 (51%)]\tLoss: 0.000030\n",
      "Train Epoch: 192 [38400/50000 (77%)]\tLoss: 0.000032\n",
      "Train Epoch: 193 [0/50000 (0%)]\tLoss: 0.000028\n",
      "Train Epoch: 193 [12800/50000 (26%)]\tLoss: 0.000118\n",
      "Train Epoch: 193 [25600/50000 (51%)]\tLoss: 0.000436\n",
      "Train Epoch: 193 [38400/50000 (77%)]\tLoss: 0.000020\n",
      "Train Epoch: 194 [0/50000 (0%)]\tLoss: 0.000100\n",
      "Train Epoch: 194 [12800/50000 (26%)]\tLoss: 0.000058\n",
      "Train Epoch: 194 [25600/50000 (51%)]\tLoss: 0.000066\n",
      "Train Epoch: 194 [38400/50000 (77%)]\tLoss: 0.000127\n",
      "Train Epoch: 195 [0/50000 (0%)]\tLoss: 0.000143\n",
      "Train Epoch: 195 [12800/50000 (26%)]\tLoss: 0.000072\n",
      "Train Epoch: 195 [25600/50000 (51%)]\tLoss: 0.000014\n",
      "Train Epoch: 195 [38400/50000 (77%)]\tLoss: 0.000045\n",
      "Train Epoch: 196 [0/50000 (0%)]\tLoss: 0.000011\n",
      "Train Epoch: 196 [12800/50000 (26%)]\tLoss: 0.000096\n",
      "Train Epoch: 196 [25600/50000 (51%)]\tLoss: 0.000032\n",
      "Train Epoch: 196 [38400/50000 (77%)]\tLoss: 0.000023\n",
      "Train Epoch: 197 [0/50000 (0%)]\tLoss: 0.000011\n",
      "Train Epoch: 197 [12800/50000 (26%)]\tLoss: 0.000108\n",
      "Train Epoch: 197 [25600/50000 (51%)]\tLoss: 0.000257\n",
      "Train Epoch: 197 [38400/50000 (77%)]\tLoss: 0.000029\n",
      "Train Epoch: 198 [0/50000 (0%)]\tLoss: 0.000066\n",
      "Train Epoch: 198 [12800/50000 (26%)]\tLoss: 0.000006\n",
      "Train Epoch: 198 [25600/50000 (51%)]\tLoss: 0.000022\n",
      "Train Epoch: 198 [38400/50000 (77%)]\tLoss: 0.000023\n",
      "Train Epoch: 199 [0/50000 (0%)]\tLoss: 0.000214\n",
      "Train Epoch: 199 [12800/50000 (26%)]\tLoss: 0.000069\n",
      "Train Epoch: 199 [25600/50000 (51%)]\tLoss: 0.000016\n",
      "Train Epoch: 199 [38400/50000 (77%)]\tLoss: 0.000014\n",
      "Train Epoch: 200 [0/50000 (0%)]\tLoss: 0.000029\n",
      "Train Epoch: 200 [12800/50000 (26%)]\tLoss: 0.000041\n",
      "Train Epoch: 200 [25600/50000 (51%)]\tLoss: 0.000055\n",
      "Train Epoch: 200 [38400/50000 (77%)]\tLoss: 0.000006\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "lr = 1.0    # Note the default learning rate is 1.0\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "def train(model, device, trainloader, criterion, optimizer, epoch, writer, log_interval):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(trainloader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        writer.add_scalar('Train Loss', loss, (epoch - 1) * len(trainloader) + batch_idx)\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(trainloader.dataset),\n",
    "                100. * batch_idx / len(trainloader), loss.item()))\n",
    "\n",
    "# set the max training epoch and log_interval(for train loss printing interval)\n",
    "# initialize the writer\n",
    "epoch = 200\n",
    "log_interval = 100\n",
    "writer = SummaryWriter(log_dir='runs/ResNet-18')\n",
    "\n",
    "# start train\n",
    "for epoch in range(1, epoch + 1):\n",
    "    train(model, device, trainloader, criterion, optimizer, epoch, writer, log_interval)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0043, Accuracy: 9383/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Accuracy of airplane: 941.0/1000.0 (94%)\n",
      "\n",
      "\n",
      "Test set: Accuracy of automobile: 974.0/1000.0 (97%)\n",
      "\n",
      "\n",
      "Test set: Accuracy of bird : 927.0/1000.0 (93%)\n",
      "\n",
      "\n",
      "Test set: Accuracy of cat  : 859.0/1000.0 (86%)\n",
      "\n",
      "\n",
      "Test set: Accuracy of deer : 947.0/1000.0 (95%)\n",
      "\n",
      "\n",
      "Test set: Accuracy of dog  : 894.0/1000.0 (89%)\n",
      "\n",
      "\n",
      "Test set: Accuracy of frog : 957.0/1000.0 (96%)\n",
      "\n",
      "\n",
      "Test set: Accuracy of horse: 960.0/1000.0 (96%)\n",
      "\n",
      "\n",
      "Test set: Accuracy of ship : 964.0/1000.0 (96%)\n",
      "\n",
      "\n",
      "Test set: Accuracy of truck: 960.0/1000.0 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test(model, device, testloader, criterion, epoch, writer):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    N_CLASSES = 10\n",
    "    class_correct = list(0. for i in range(N_CLASSES))\n",
    "    class_total = list(0. for i in range(N_CLASSES))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(testloader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "            \n",
    "            _, pred = output.max(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "\n",
    "            c = (pred == target).squeeze()\n",
    "            for i in range(len(target)):\n",
    "                _target = target[i]\n",
    "                class_correct[_target] += c[i].item()\n",
    "                class_total[_target] += 1\n",
    "\n",
    "\n",
    "    test_loss /= len(testloader.dataset)\n",
    "\n",
    "    # writer.add_scalar('Test Loss', test_loss, epoch - 1)\n",
    "    # writer.add_scalar('Test Accuracy', 100. * correct / len(testloader.dataset), epoch - 1)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))\n",
    "    \n",
    "    for i in range(N_CLASSES):\n",
    "        print('\\nTest set: Accuracy of {:5s}: {}/{} ({:.0f}%)\\n'.format(\n",
    "        classes[i], class_correct[i], class_total[i],\n",
    "        100. * class_correct[i] / (class_total[i]+1)))\n",
    "\n",
    "# start test\n",
    "test(model, device, testloader, criterion, epoch=200, writer=writer)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
